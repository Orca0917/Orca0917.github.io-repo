---
title: "[AI Math] 통계학"
excerpt: "모수의 개념과 모수를 추정하는 방법인 최대가능도 추정법에 대한 소개"

categories:
  - aimath
tags:
  - [AI, Naver, BoostCamp, Math]
toc: true
toc_sticky: true
 
date: 2022-01-20 01:00:00
last_modified_at: 2022-01-20 01:00:00
---
📌 **알립니다!**<br>
이번에 작성되는 글은 **네이버 부스트캠프 AI Tech**를 수강하며 정리하는 글입니다.<br>
여기서 존재하는 강의 자료의 출처는 네이버 부스트코스/캠프에게 있습니다.
{: .notice--info}

# 모수
> Wikipedia 에서 모수의 정의   
> 수학과 통계학에서 어떤 시스템이나 함수의 특정한 성질을 나타나내느 변수, 일반적으로 \\(\theta\\)로 표시한다.

통계적 모델링은 적절한 가정위에서 확률분포를 추정하는 것이 목표이며, 기계학습과 통계학이 공통적으로 추구하는 목표이다. 데이터 만을 이용해서 정답의 분포를 알아내는 것은 힘들고 실제로 사용할 분포의 종류도 많다보니 어떤 확률분포를 사용해서 모델링하는지도 중요한 문제가 된다. 그렇기 때문에, 근사적으로 확률분포를 추정할 수 밖에 없다.

이런 예측모형의 목적은 확률분포를 정확하게 맞추기보다는 데이터와 추정방법의 불확실성을 고려하여 예측의 위험을 최소화 하는 것이다.

모수는 영어로 parameter라고 표기하고 가장 흔한 예시인 정규분포를 예시로 들어보자. 정규분포는 2개의 매개변수인 평균(\\(\mu\\))와 분산(\\(\sigma^2\\))에 의해서 모양이 결정된다. 이때 사용되는 매개변수를 모수라고 말한다. 다시 말해, 특정한 확률변수에 사용되는 매개변수를 모수라고 표현한다.

- 모수적 방법론  
데이터가 특정확률분포를 따른다고 선험적으로 가정하고 그 분포를 결정하는 모수를 추정하는 방법을 모수적 방법론이라고 한다.

- 비모수 방법론  
특정 확률분포를 가정하지 않고 데이터에 따라 모델의 구조 및 모수의 개수가 유연하게 바뀌는 것을 비모수 방법론이라 부른다. 여기서 비모수는 모수가 없다고 생각하면 안되고 모수가 무한히 많거나 모수의 개수가 데이터에 따라서 바뀌는 경우 비모수 방법론이라고 한다. 대부분의 기계학습 방법론은 이 비모수 방법론에 속한다.

이렇게 모수적/비모수 방법론을 구별하는 기준은 어떤 가정을 미리 부여하는지에 따라 구별이 된다.

<br>

# 확률분포 가정
확률분포를 가정하기 위해서 먼저 히스토그램이나 통계치를 통해 데이터의 모양을 관찰한다. 다음 5가지의 예시를 살펴보자.

- 데이터가 2개의 값만 가지는 경우: 오직 두가지의 가능한 결과만 일어나는 것을 보아 베르누이 분포를 따른다고 가정할 수 있다.
- 데이터가 \\(n\\) 개의 이산적인 값을 가지는 경우: 카테고리 분포 또는 다항분포로 가정할 수 있다.
- 데이터가 [0, 1]사이의 실수 값을 갖는 경우: 두 매개변수 \\(\alpha , \beta \\)에 따라 [0, 1]구간에서 정의되는 연속확률 분포인 베타분포를 따른다고 가정할 수 있다.
- 데이터가 0 이상의 값을 가지는 경우: 2개의 매개변수로 양의 실수값을 갖는 감마분포나 로그정규분포를 가정할 수 있다.
- 데이터가 실수(\\(\mathbb{R}\\))전체에서 값을 갖는 경우: 정규분포나 연속확률분포인 라플라스분포를 가정해볼 수 있다.

단, 확률분포를 가정할 때 단순히 기계적으로 확률분포를 가정해서는 안되며, 데이터를 생성하는 원리를 먼저 고려하는 것이 원칙이다. 또한 각 분포마다 검정하는 방법이 있기에 모수를 추정한 후에 반드시 통계적 검정 절차를 거쳐야 한다.

<br>

# 데이터를 통한 모수의 추정
위에서 데이터의 확률분포를 가정하였다면, 다음에는 모수를 추정해볼 수 있다. 이번에도 정규분포를 예시로 한 번 들어보자. 앞서서 말했듯이 정규분포의 모수는 평균(\\(\mu\\))와 분산(\\(\sigma^2\\))이며, 이를 추정하는 통계량은 다음과 같이 계산할 수 있다.

$$ \bar{X} = \frac{1}{N}\sum_{i=1}^{N}X_i \qquad \mathbb{E}[\bar{X}] = \mu $$

위의 수식은 표본평균 \\(\bar{X}\\)를 구하는 것으로 주어진 데이터의 산술평균을 통해서 계산한다. 그로부터 구해진 표본평균들의 기댓값은 모평균 \\(\mu\\)와 일치한다.

$$ S^2 = \frac{1}{N-1}\sum_{i=1}^{N}(X_i-\bar{X})^2 \qquad \mathbb{E}[S^2] = \sigma^2 $$

위의 수식은 표본분산을 구하는 것으로, 실제 데이터와 표본평균의 차이의 제곱들의 합을 전체 데이터의 개수에서 1을 뺀 \\(N-1\\) 로 나누어준다. 이때 전체 데이터의 개수 \\(N\\)이 아닌 \\(N-1\\) 로 나누어주는 이유는 불편추정량을 구하기 위해서이다.

이와 관련되어서 더 자세한 것은 다음 페이지에 잘 나와있다.  
[❓ 왜 표본(샘플)의 분산에서는 n이 아닌 n-1로 나눌까?](https://blog.naver.com/sw4r/221021838997)

다시 돌아와서, **표본평균과 표본분산의 확률분포를 표집분포**(Sampling distribution)라 부르며, 특히 표본평균의 표집분포는 데이터의 개수 \\(N\\)이 커질수록 정규분포 \\(N(\mu, \sigma^2/N)\\))을 따른다. 이를 **중심극한정리** (Central Limit Theorem)이라 부르며 모집단의 분포가 정규분포를 따르지 않아도 성립한다.

<br>

# 최대가능도 추정법
정규분포의 모수인 표본평균이나 표본분산은 중요한 통계량이지만, 정규분포가 아닌 확률분포에 따라서는 사용하는 모수가 다르기 때문에 적절한 통계량이 달라지게 된다. 이를 보완하기 위해서 이론적으로 가장 가능성이 높은 모수를 추정하는 방법중 하나인 **최대가능도 추정법**(Maximum Likelihood Estimation, MSE)에 대해서 소개한다.

MLE는 주어진 확률분포를 어떤식으로 가정하냐에 따라 상관없이 이론적으로 가장 가능성이 높은 모수를 추정해준다. 모수 \\(\theta \\)에 대해서 MLE를 수행하는 수식으 다음과 같다.

$$ \hat{\theta}_{MLE}=\underset{\theta}{\text{argmax}}L(\theta ; x)=\underset{\theta}{\text{argmax}}P(x|\theta) $$

두번째 식은 데이터 \\(x\\) 가 주어진 상황에서 \\(\theta\\)를 변형시킴에 따라 값이 바뀌는 함수라고 이해할 수 있고 이 가능도 함수는 전에 배운 확률밀도함수나 확률질량함수와 비슷하다고 볼 수 있다. 다른 것은 관점의 차이이다.

- 확률밀도함수  
모수 \\(\theta\\)가 있을 때, 데이터 \\(x\\) 에 대한 관점으로 해석
- 가능도함수  
데이터 \\(x\\)에 대해 모수 \\(\theta\\)를 변수로 둔 함수. 다시 말하자면, 모수 \\(\theta\\)를 따르는 분포가 \\(x\\)를 관찰할 가능성을 뜻한다. 하지만 이것을 확률로 해석하면 안된다. 그 이유는 \\(\theta\\) 에 대해서 적분을 하거나, 다 더하였을 때 1이 나오지 않기 때문에 확률로 해석해서는 안되고, 크고 작음의 대소비교가 가능한 함수로 이해를 해야한다.

데이터 \\(x\\)의 집합 \\(X\\)의 행벡터가 독립적으로 추출되었을 경우, 로그 가능도를 최적화할 수 있다. 먼저 독립적으로 추출된 경우, 각 확률을 곱으로 나타낼 수 있는데, 로그의 성질을 이용하면 각 확률의 합으로 나타낼 수 있다. 다음 수식을 살펴보자. **여기서 사용되는 로그는 밑이 \\(e\\) 인 자연로그이다.**

$$ L(\theta ; X) = \prod_{i=1}^{n}P(x_i|\theta) \qquad \Rightarrow \qquad \text{log}L(\theta ; X) = \sum_{i=1}^{n}\text{log}P(x_i|\theta) $$

> 그렇다면 왜 로그를 사용하는 것일까?

1. 로그가능도를 최적화하는 모수 \\(\theta\\) 와, 원래 가능도함수의 모수 \\(\theta\\) 모두 가능도를 최적화하는 MLE가 된다.
2. 데이터의 숫자가 적으면 상관없지만, 데이터의 숫자가 수억단위가 된다면 컴퓨터의 정확도로 가능도를 계산할 수 없다. 예를 들어서 0과 1사이의 수를 수억번 곱셈을 진행한다고 하면 컴퓨터는 너무 낮은 자리수의 연산을 오차때문에 하기가 힘들어진다.
3. 데이터가 독립일 경우, 로그를 사용하면 가능도의 곱셈을 덧셈으로 표현하여 컴퓨터로도 연산이 가능해진다. (연산의 오차방지)
4. 경사하강법으로 가능도를 최적화를 하면 미분연산을 사용하는데, 로그가능도를 사용하면 그때의 연산량을 \\(O(n^2)\\) 에서 \\(O(n)\\) 으로 줄여준다.

일반적으로 로그가능도를 사용하여 미분을 하게되면 극댓값을 찾아주기 때문에 음의 로그가능도를 사용하여 최적화를 진행해야한다.

## 예제: [연속확률분포] 정규분포
최대가능도를 이용하여 정규분포의 모수를 구해보자. 정규분포를 따르는 확률변수 \\(X\\) 로 부터 독립적인 표본 \\({x_1, \dots, x_n}\\)을 얻었을 때, 최대가능도 추정법을 이용하여 모수를 결정하자. 정규분포의 모수는 앞서 확인했듯이 평균값과 분산값 2가지로 이루어져있다.

따라서, 구하고자 하는 모수를 \\(\theta\\)라고 하면 \\(\theta = \mu, \sigma^2\\) 이다. 이번에는 최대가능도 함수를 이용하여 수식을 표현해보면 다음과 같다.

$$ \hat{\theta}_{MLE} = \underset{\theta}{\text{argmax}} L(\theta ; x) = \underset{\mu, \sigma^2}{\text{argmax}} P(X|\mu, \sigma^2) $$

위의 가능도함수에 로그를 씌워 로그가능도 함수를 계산하면 다음과 같다.

\begin{aligned}
\text{log}L(\theta ; X) = \sum_{i=1}^{n}\text{log}P(x_i|\theta) &= \sum_{i=1}^{n}\text{log}\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{|x_i-\mu|^2}{2\sigma^2}}\\\\\\
&=-\frac{n}{2}\text{log}2\pi \sigma^2-\sum_{i=1}^{n}\frac{\|x_i-\mu\|^2}{2\sigma^2}
\end{aligned}

위의 마지막 식에서 가능도를 최적화하기 위해서 미분을 이용한 경사하강법을 수행하며 그 미분값이 0이되는 지점을 찾으면 된다. 모수가 평균과 분산으로 총 2개이기 때문에 각각에 대하여 편미분을 수행한다.

먼저, 로그가능도 함수에서 평균값인 \\(\mu\\) 를 이용하여 편미분을 해보자. 앞의 항은 상수화가 되어서 사라지게 되고, 뒤의 항만 미분이 되고, 제곱의 2가 분모인 2와 나누어 떨어져 사라지는 것을 확인해보자.

$$ 0 = \frac{\partial \text{log}L}{\partial \mu}=-\sum_{i=1}^{n}\frac{x_i-\mu}{\sigma^2} $$

$$ \hat{\mu}_{MLE}=\frac{1}{n}\sum_{i=1}^{n}x_i $$

그 다음, 분산에 대해서 편미분을 진행하면 다음과 같이 전개 된다.

$$ 0 = \frac{\partial\text{log}L}{\partial \sigma} = -\frac{n}{\sigma}+ \frac{1}{\sigma^3}\sum_{i=1}^{n}|x_i-\mu|^2 $$

$$ \hat{\sigma^2}_{MLE} = \frac{1}{n}\sum_{i=1}^{n}(x_i-\mu)^2 $$

여기서 마지막에 표본분산과 다르게 \\(n-1\\)이 아닌 다시 \\(n\\) 으로 나는 이유는 **가능도의 경우 불편추정량을 보장하지 않기 때문**이다.

## 예제: [이산확률분포] 카테고리분포
카테고리 분포는 베루누이 분포라 하는 2개의 값중 하나만 선택하게 되는 확률분포의 \\(d\\)차원으로 확장한 개념이다. 이 카테고리 분포 Multinoulli(x; \\(p_1, \dots, p_d\\))를 따르는 확률변수 \\(X\\)로 부터 독립적인 표본 \\({x_1, \dots, x_n}\\)을 얻었을 때 최대가능도 추정법을 이용해서 모수를 추정해보자.

위에서 했던것과 비슷하게 먼저 최대가능도 함수먼저 나타내보면 다음과 같다.

$$ \hat{\theta}_{MLE}=\underset{p_1, \dots, p_d}{\text{argmax}}\,\,\text{log}P(x_i|\theta) = \underset{p_1, \dots, p_d}{\text{argmax}}\,\,\text{log}\left ( \prod_{i=1}^{n}\prod_{k=1}^{d}p_k^{x_{i,k}} \right ) $$

\\(p_1, \dots, p_d\\) 는 카테고리 분포의 모수로서 각 차원에서 값이 1 또는 0이 될 확률을 말한다. 또한 카테고리분포의 모수는 다음 제약식을 반드시 만족해야 한다.

$$ \sum_{k=1}^{d}p_k=1 $$

다시 위의 로그가능도 함수에서, 가장 마지막 product부분만 꺼내서 조금 더 간단하게 표현해보자.

$$ \text{log}\left ( \prod_{i=1}^{n}\prod_{k=1}^{d}p_k^{x_{i,k}} \right )=\sum_{k=1}^{d}n_k\,\text{log}\,p_k \qquad n_k = \sum_{i=1}^{n}x_{i,k} $$

이 식은 주어진 각 데이터들에 대해서 어떤 k번째 차원의 값이 1인 개수를 카운팅하는 것이다. 오른쪽의 제약식을 만족하면서 왼쪽의 목적식을 최대화 시키고자 하는것이 목표이다. 제약식이 있기 때문에 목적함수를 간단하게 미분하는 것은 불가능하고, **라그랑주 승수법**을 이용하여 제약식을 없애야 한다.

‼ 라그랑주 승수법 <br><br>
라그랑주 승수법은 제약이 있는 최적화 문제를 푸는법으로, 최적화 하려는 값에 형식적인 라그랑주 승수항을 더하여 제약된 문제를 제약이 없는 문제로 바꾸는 것을 말한다. 라그랑주 승수법의 가정은 다음과 같다.<br>"어떤 제약조건 \\(g\\)를 만족하는 \\(f\\)의 최솟값 또는 최댓값은 \\(f\\)와 \\(g\\) 가 접하는 지점에 있을 수 있다."
{: .notice--warning}

이제 라그랑주 승수항을 추가하여 제약이 없는 문제로 바꾸면 다음과 같이 변한다.

$$ L(p_1,\dots,p_k, \lambda)=\sum_{k=1}^{d}n_k \text{ log}p_k+\lambda(1-\sum_{k}p_k) $$

여기서 우리가 구하고자 하는 모수, \\(p_1,\dots,p_k\\) 와 \\(\lambda\\)에 대해서 각각 편미분을 진행한다.

$$ 0 = \frac{\partial L}{\partial p_k}=\frac{n_k}{p_k}-\lambda\qquad0=\frac{\partial L}{\partial \lambda}=1-\sum_{k=1}^{d}p_k $$

$$ p_k=\frac{n_k}{\sum_{k=1}^{d}n_k} $$

마지막의 식에서 분모가 가리키는 것은 데이터의 개수인 \\(n\\) 값이고, 결국 말하는 것은 카데고리의 분포의 MLE는 각각의 경우에 해당하고 각각의 차원에 해당하는 데이터의 카운터 숫자의 비율임을 알 수 있다.

## 딥러닝에서 최대가능도 추정법
최대 가능도 추정법을 이용해서 기계학습모델을 학습에 이용할 수 있다. 딥러닝 모델의 가중치들을 다시 \\(\theta\\) 라고 표기하면 분류문제에서 softmax벡터는 카테고리 분포의 모수 \\(p_1,\dots,p_k\\)를 모델링한다. 원핫벡터로 표현한 정답레이블 \\(y = (y_1, \dots, y_k)\\)을 관찰데이터로 이용하여 확률분포인 softmax벡터의 로그가능도를 최적화하는 것이 가능하다.

$$ \hat{\theta}_{MLE}=\underset{\theta}{\text{argmax}}\frac{1}{n}\sum_{i=1}^{n} \sum_{k=1}^{K}y_{i,k}\text{ log}(MLP_{\theta}(X_i)_k) $$

<br>

# 확률분포의 거리
MLE로 추정하는 많은 학습모델 방법론은 확률분포의 거리를 최적화하는 것과 굉장히 밀접하게 연관이 되어 있다. 기계학습에서 사용되는 손실함수들은 모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 유도된다.

데이터 공간에 2개의 확률분포 \\(P(x), Q(x)\\) 가 있을 때 두 확률분포 사이의 거리를 계산할 때 다음과 같은 함수를 사용한다.
- 총변동거리
- 쿨백-라이블러 발산
- 바슈타인 거리

## 쿨백-라이블러 발산

> 쿨백-라이블러 발산(Kullback–Leibler divergence, KLD)은 두 확률분포의 차이를 계산하는 데에 사용하는 함수로, 어떤 이상적인 분포에 대해, 그 분포를 근사하는 다른 분포를 사용해 샘플링을 한다면 발생할 수 있는 정보 엔트로피 차이를 계산한다. - wikipedia

- [이산확률변수]  

$$ \mathbb{KL}(P||Q)=\sum_{x\in X}P(x)\text{log}(\frac{P(x)}{Q(x)}) $$

- [연속확률변수]

$$ \mathbb{KL}(P||Q)= \int_{x}P(x)\text{log}(\frac{P(x)}{Q(x)})dx $$

쿨백-라이블러 발산은 다음과 같이 분해할 수 있는데, 앞의 식을 **크로스 엔트로피**, 뒤의 식을 **엔트로피**라고 부른다. 이는 분류문제에서 정답레이블을 P, 모델예측을 Q라고 두면 최대가능도 추정법은 쿨백-라이블러 발산을 최소화하는것과 같다.

$$ \mathbb{KL}(P||Q)= -\mathbb{E}_{x\sim Q(x)}[\text{log}Q(x)] + \mathbb{E}_{x\sim P(x)}[\text{log}P(x)] $$

<br>

# References

[📘 베르누이 분포 - wikipedia](https://ko.wikipedia.org/wiki/%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4_%EB%B6%84%ED%8F%AC)

[📘 정규분포 - wikipedia](https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C_%EB%B6%84%ED%8F%AC)

[📘 라그랑주 승수법 - wikipedia](https://ko.wikipedia.org/wiki/%EB%9D%BC%EA%B7%B8%EB%9E%91%EC%A3%BC_%EC%8A%B9%EC%88%98%EB%B2%95)

[📘 laplace distribution - - wikipedia](https://en.wikipedia.org/wiki/Laplace_distribution)

[📘 감마 분포 - wikipedia](https://ko.wikipedia.org/wiki/%EA%B0%90%EB%A7%88_%EB%B6%84%ED%8F%AC)

[📘 베타 분포 - wikipedia](https://ko.wikipedia.org/wiki/%EB%B2%A0%ED%83%80_%EB%B6%84%ED%8F%AC)

[📘 라그랑주 승수법 - tistory](https://untitledtblog.tistory.com/96)




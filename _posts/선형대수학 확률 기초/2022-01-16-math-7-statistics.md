---
title: "통계 : 데이터의 확률분포를 추정하기 위한 방법"
excerpt: "확률분포에서 사용되는 모수가 무엇인지 데이터의 확률분포를 어떻게 잘 추정할 수 있는지 살펴봅니다. 특히 확률분포의 모수를 추정하기 위한 최대가능도 추정법에 대해서 설명합니다. 예측한 확률분포와 실제 확률분포가 어떻게 다른지 계산하는 쿨백-라이블러 발산과 엔트로피와의 관계도 함께 알아봅시다!"

categories:
  - aimath
tags:
  - [AI, BoostCamp, Math]
toc: true
toc_sticky: true
 
date: 2022-01-20 01:00:00
last_modified_at: 2022-07-11 00:00:00
---
![image](https://user-images.githubusercontent.com/91870042/178300444-c859cce9-c314-447e-904d-ece70ab388bd.png){: .align-center width="100%"}

바로 이전 [확률 포스팅](https://killerwhale0917.github.io/aimath/math-6-probability/) 에서 딥러닝으로 알아내고 싶은 정보가 바로 **데이터를 가장 잘 표현하는 확률분포**였습니다. 이 글에서는 주어진 데이터를 사용해서 확률분포를 정확하게 알아내는 것은 불가능하기 때문에 통계적 모델링을 통해 확률분포를 근사적으로 추정하는 방법에 대해서 알아보겠습니다.

<br>

# 확률분포의 추정

앞으로 확률분포를 추정하는 과정을 거치게 되는데, 먼저 `모수(parameter)`에 대해서 알고 있어야 합니다. 모수는 매개변수라고도 하며, 통계학에서는 어떤 함수의 특정한 성질을 나타내는 변수를 말합니다. 가장 대표적인 예시로 정규분포를 들 수 있습니다. 정규분포는 수식으로 $\mathcal{N}(\mu,\,\sigma^2)$ 로 표현합니다. 여기서 사용되는 평균값 $\mu$ 와 분산 $\sigma^2$ 이 정규분포의 모수입니다.

이제 확률분포를 추정해야 하는데, 그 방법을 확률분포를 가정하는지에 따라서 2가지 방법으로 나누어볼 수 있습니다.

- 모수적 방법론 : 데이터가 특정 확률분포를 따른다고 선험적으로 가정하고, 그 확률분포의 모수를 추정하는 방법
- 비모수적 방법론 : 특정 확률분포를 가정하지 않고, 데이터에 따라서 모델의 구조나 모수의 개수가 유연하게 바뀌는 추정 방법

<br>

모수적 방법론에서 확률분포를 가정하는 것은 먼저 데이터의 분포(히스토그램, 그래프 등)를 살펴보고 정하게 됩니다. 예를 들어 데이터가 단 2개의 값만 가질 수 있다면 베르누이 분포를, 실수 전체에서 값을 갖는 경우에는 정규분포를, 이산적인 값을 갖는 경우는 카테고리 분포를 떠올려볼 수 있습니다.

추가로, 비모수적 방법론은 모수가 너무 많거나 데이터에 따라서 모수의 수가 바뀌는 것이지 모수가 없다는 것을 의미하지 않습니다. 여기 2가지 방법론에서 현재 **기계학습은 비모수적 방법론을 주로 채택**하고 있습니다.

<br>

## 🐟 모수적 방법론

확률분포를 먼저 가정하고 모수를 추정하는 것이 모수적 방법론이었습니다. 이번에는 예시를 통해서 함께 살펴보고자 합니다. 어떤 데이터가 **정규분포**를 따른다고 가정합시다. 정규분포의 모수는 앞서 설명했듯이 평균과 분산값입니다. 주어진 데이터만을 사용해서 평균과 분산을 구할 때, **표본평균**과 **표본분산**을 사용해 볼 수 있습니다.

$$
\bar{X} = \frac{1}{N}\sum_{i=1}^{N}X_i \qquad S^2 = \frac{1}{N - 1}\sum_{i=1}^{N}(X_i-\bar{X})
$$

- $\bar{X}$ : 표본 평균
- $S^2$ : 표본 분산
- $N$ : 샘플 데이터의 수
- $X$ : 데이터 집합

여기서 표본분산을 계산할 때, $N$ 이 아닌 $N-1$ 로 나누어주는 것은 불편 추정량을 구하기 위해서입니다. 불편추정량, 자유도에 대한 얘기는 여기서 다루지는 않겠습니다😂. 각 표본평균과 표본분산의 기댓값은 모평균과 모분산과 동일하며 우리는 수많은 샘플링을 통해서 그 분포가 정규분포와 가까워지게 학습을 시킬 것입니다.

위의 표본평균과 표본분산을 이용해서 만든 확률분포를 `표집분포`라고 하며 **표본분포와 다른 용어임**을 반드시 인지하고 있어야 합니다. 표집분포는 $N$ 이 커질수록 분산이 0에 가까워지는 정규분포 $\mathcal{N}(\mu,\,\sigma^2/N)$ 를 따릅니다. 이 원리는 모집단의 데이터분포가 정규분포가 아니더라도 성립하며 이를 `중심극한정리`라고 부릅니다. 단, **표본분포**는 $N$이 아무리 커져도 정규분포를 따르지 않을 수 있습니다.

<br>

## 🐋 비모수적 방법론

위의 모수적 방법론에서 표본평균과 표본분산을 사용했던 것은 정규분포를 사용한다고 가정하였을 때만 가능하였습니다. 하지만 확률분포마다 사용하는 모수가 다르기 때문에 찾아야 하는 통계량이 문제마다 달라지게 됩니다. 이 때 사용할 수 있는 것이 `최대가능도 추정법(MLE)` 이며 이론적으로 가장 가능성이 높은 모수를 추정합니다.

$$
\hat{\theta}_{\text{MLE}} = \underset{\theta}{\text{argmax}}\;L(\theta\,;\mathbf{x}) = \underset{\theta}{\text{argmax}}\;\mathbb{P}(\mathbf{x}\,\vert\,\theta)
$$

- $\theta$ : 모수(parameter)
- $L$ : 가능도 함수
- $\mathbf{x}$ : 데이터

조금은 생소하게 와닿을 수 있는 위의 수식을 풀어서 써보겠습니다. 위에서 $L$ 함수는 주어진 데이터 $\mathbf{x}$ 에 대해 **모수를 추정하는 함수**이며 기존의 확률밀도함수, 확률질량함수와 유사하다고 생각해도 괜찮습니다. 다른 방법으로 조건부확률로도 해석할 수 있으며 **모수 $\theta$ 를 따르는 분포가 데이터 $\mathbf{x}$ 를 관찰할 가능성**이라고 볼 수 있습니다.

데이터 $\mathbf{x}$ 를 관찰할 가능성이 높아야 올바른 확률분포를 추정한 것이기 때문에 $\theta$ 값도 정확하게 추정이 되어야 합니다. 그 표시를 위해 $\text{argmax}$ 를 사용하였습니다. 여기서 주의할 것은 이 가능도 함수의 결과를 확률로 해석해서는 안 되는 것입니다. 모수에 대해서 급수를 취하거나 적분을 하였을 때 그 값이 1이 되는 개념이 아니기 때문에 확률이 아닌 가능도 정도로 이해해야 합니다.

---

이제 데이터 하나 $\mathbf{x}$ 가 아닌 데이터 집합 $\mathbf{X}$ 를 대입하여 이해해 보겠습니다. 각 데이터를 추출하는 것은 독립적이기 때문에 아래와 같이 확률의 곱으로 나타낼 수 있습니다. $\log$ 에 대해서는 바로 아래에서 설명드리겠습니다!

$$
L(\theta\,; \mathbf{X}) = \prod_{i=1}^{n} \mathbb{P}(\mathbf{x}_i\,\vert\,\theta) \quad \Rightarrow \quad \log L(\theta\,; X) = \sum_{i=1}^{n}\log \mathbb{P}(\mathbf{x}_i\,\vert\,\theta)
$$

왜 가능도함수 결과에 $\log$ 를 사용하였을까요? 사실 로그가능도함수를 최적화하는 것과 가능도함수를 최적화하는 것이 동일합니다. 또한 데이터의 수가 적으면 괜찮지만, 데이터의 수가 1억 개, 10억 개라고 가정해 봅시다. 확률의 값이 0 ~ 1사이의 실숫값이며 이 값들이 1억 번 이상 곱해진다면 컴퓨터의 한계로 정확한 계산이 불가능하고 오차가 발생할 것입니다. 하지만, $\log$ 를 사용하여 덧셈으로 바꾸어준다면 이런 문제를 해결해 줄 수 있습니다.

두 번째로, 모수 $\theta$ 를 찾기 위해 학습하는 과정에서 경사하강법을 사용하는데, 일반 가능도함수를 미분할때 연산량이 $O(n^2)$ 이 소비됩니다. 하지만, $\log$ 를 통해 $O(n)$ 으로 줄여줄 수 있습니다. 경사하강법은 목적식을 최소화하는데 사용했지만, 이번에는 가능도를 최대화하는데 사용해야 합니다. 그렇기에 학습할 때는 음수를 취하여 가능도를 최대화시켰습니다. 이를 음의 로그가능도라고 합니다.

<br>

### 예제: 정규분포

> 정규분포를 따르는 확률변수 $X$ 로 부터 독립적인 표본을 얻었을 때, 최대가능도 추정법을 사용하여 모수 추정

정규분포를 따르기 때문에, 확률분포에 사용되는 모수는 평균과 분산값임을 알 수 있습니다. 그렇기에 먼저 최대가능도 추정법 수식은 $\theta$ 를 평균과 분산값으로 변경하여 다음과 같이 작성할 수 있습니다.

$$
\hat{\theta}_{\text{MLE}} = \underset{\theta}{\text{argmax}}\;L(\theta\,;\mathbf{x}) = \underset{\mu,\, \sigma^2}{\text{argmax}}\;\mathbb{P}(\mathbf{X}\,\vert\,\mu,\,\sigma^2)
$$

그리고 계산의 이점을 가져가기 위해 로그를 취하고, 정규분포식에 모수를 대입하면 아래와 같습니다.

$$
\begin{aligned}
\log L(\theta\,; \mathbf{X}) = \sum_{i=1}^{n}\log \mathbb{P}(\mathbf{x}_i\,\vert\,\theta) 
&= \sum_{i=1}^{n}\log\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{\vert \mathbf{x}_i-\mu \vert^2}{2\sigma^2}}\\
&=-\frac{n}{2}\log2\pi \sigma^2-\sum_{i=1}^{n}\frac{\vert \mathbf{x}_i-\mu \vert^2}{2\sigma^2}
\end{aligned}
$$

이제 가능도를 최대화시켜야 하기 때문에, 가능도를 최대화 시키기 위한 모수인 평균과 분산에 대해 각각 미분을 하여 최대가 되는 방향으로 학습을 시킵니다. 두 미분 값이 모두 0이 되는 극댓값을 찾도록 하면 가능도를 최대화할 수 있습니다.

$$
0 = \frac{\partial \log L}{\partial \mu}=-\sum_{i=1}^{n}\frac{\mathbf{x}_i-\mu}{\sigma^2}
$$

$$
0 = \frac{\partial\log L}{\partial \sigma} = -\frac{n}{\sigma}+ \frac{1}{\sigma^3}\sum_{i=1}^{n}\vert \mathbf{x}_i-\mu \vert^2
$$

위의 식을 평균과 분산에 대해서 남기고 정리를 하면 아래와 같이 나타납니다. 이때 표본분산과 달리, MLE를 사용하여 구한 분산은 불편추정량을 보장하지 않기 때문에 $n-1$ 이 아닌 $n$ 으로 나눈 것을 확인할 수 있습니다.

$$
\begin{aligned}
  \hat{\mu}_\text{MLE} &= \frac{1}{n}\sum_{i=1}^{n}\mathbf{x}_i \\
  \hat{\sigma}^2_\text{MLE} &= \frac{1}{n}\sum_{i=1}^{n}(\mathbf{x}_i - \mu)^2
\end{aligned}
$$

<br>

### 예제: 카테고리분포

카테고리 분포는 베르누이 분포라 하는 확률분포를 $d$ 차원으로 확장한 개념입니다. 이 카테고리 분포 $\text{Multinoulli}(\mathbf{x}\,; p_1, \dots, p_d)$ 를 따르는 확률변수 $X$ 로 부터 독립적인 표본을 얻었을 때 최대가능도 추정법을 이용해서 모수를 추정해 봅시다.

카테고리 분포의 다른 특징으로는 $p_1, \dots, p_d$ 를 모두 더했을 때 1이 되는 성질이 있습니다. 또한, 여기서 추출한 독립적인 표본은 원핫벡터로 0 또는 1로만 구성되어 있습니다. 이 성질도 함께 사용해서 문제를 해결해 보겠습니다.

마찬가지로 동일하게 최대가능도 함수에 모수와 카테고리 분포 함수를 대입하여 표현해 봅시다.

$$
\hat{\theta}_{\text{MLE}} = \underset{p_1,\,\dots,\,p_d}{\text{argmax}}\;\log \mathbb{P}(\mathbf{x}_i\,\vert\,\theta) = \underset{p_1,\,\dots,\,p_d}{\text{argmax}}\;\log \left ( \prod_{i=1}^{n}\prod_{k=1}^{d}p_k^{x_{ik}} \right )
$$

- $p_k^{x_{ik}}$ : 주어진데이터 $\mathbf{x}_i$ 의 $k$ 번째 차원 값

아까 말했듯이 카테고리 분포의 성질이자 제약조건으로 모든 확률의 합이 1이 된다는 특징이 있었습니다. 추가로 급수로 합을 얻는 걸로 보아 확률질량함수임을 유추해 볼 수 있습니다. 아래는 그 특징을 표현한 수식이며 이것이 카테고리 분포의 제약조건입니다.

$$ 
\sum_{k=1}^{d}p_k=1
$$

이번에는 처음 표현한 식에서 등장한 곱연산들을 모두 $\log$ 의 성질을 사용해 합 연산으로 변경해 주겠습니다.

$$
\log\left ( \prod_{i=1}^{n}\prod_{k=1}^{d}p_k^{x_{ik}} \right )=\sum_{k=1}^{d}n_k\,\log\,p_k \qquad n_k = \sum_{i=1}^{n}x_{ik}
$$

- $n_k$ : 데이터 $\mathbf{x}$에서 $k$ 번째 값이 1인 것의 수

현재 목적식이 완성되었습니다! 위의 모든 확률의 합이 1이 되는 제약식을 만족하면서 왼쪽의 목적식을 최대화 시키고자 하는 것이 목표입니다. 하지만 제약식이 있기 때문에 목적함수를 간단하게 미분하는 것은 불가능하고, **라그랑주 승수법**을 이용하여 제약식을 없애야 합니다.

라그랑주 승수법 <br>
라그랑주 승수법은 제약이 있는 최적화 문제를 푸는 법으로, 최적화 하려는 값에 형식적인 라그랑주 승수항을 더하여 제약된 문제를 제약이 없는 문제로 바꾸는 것을 말한다. 라그랑주 승수법의 가정은 다음과 같다.<br>"어떤 제약조건 $g$ 를 만족하는 $f$ 의 최솟값 또는 최댓값은 $f$ 와 $g$ 가 접하는 지점에 있을 수 있다."
{: .notice--info}

이제 라그랑주 승수법을 사용하여 제약이 없는 문제로 바꾸면 다음과 같이 바꿀 수 있습니다.

$$
L(p_1,\,\dots,\,p_k, \lambda)=\sum_{k=1}^{d}n_k \log\;p_k + \lambda(1 - \sum_{k}p_k)
$$

제약조건이 없는 새로운 목적식이 등장하였으니 경사하강법을 사용하기 위해 사용된 모수인 $p_1,\dots,p_k$ 과 $\lambda$ 에 대해서 각각 편미분을 진행합니다.

$$
0 = \frac{\partial L}{\partial p_k}=\frac{n_k}{p_k}-\lambda\qquad0=\frac{\partial L}{\partial \lambda}=1-\sum_{k=1}^{d}p_k
$$

$$
p_k = \frac{n_k}{\sum_{k=1}^{d} n_k}
$$

마지막의 식에서 분모가 가리키는 것은 데이터의 개수인 $n$ 값이고, 결국 말하는 것은 카테고리의 분포의 MLE는 각각의 차원에 해당하는 경우의 수의 비율임을 알 수 있습니다.

<br>

## 🐳 딥러닝에서 최대가능도 추정법

지금까지 알아본 최대 가능도 추정법을 그대로 기계학습모델을 학습에 이용할 수 있습니다. 딥러닝 모델의 가중치들을 다시 $\theta$ 라고 표기하면 분류 문제에서 softmax 벡터는 카테고리 분포의 모수 $p_1,\dots,p_k$를 모델링할 수 있습니다.

원핫벡터로 표현한 정답 레이블을 $y = (y_1, \dots, y_k)$ 이라고 한다면 이를 다시 관찰 데이터로 이용하여 확률분포인 softmax벡터의 로그가능도를 최적화하는 것이 가능합니다.

$$
\hat{\theta}_{\text{MLE}} = \underset{\theta}{\text{argmax}} \frac{1}{n} \sum_{i=1}^{n} \sum_{k=1}^{K} y_{ik} \log (\text{MLP}_{\theta}(\mathbf{x}_{ik}))
$$

- $n$ : 데이터의 수
- $K$ : 분류하는 클래스의 개수
- $y_{ik}$ : $i$ 번째 데이터의 라벨에 대한 $k$ 번째 클래스 값
- $\text{MLP}_\theta (\mathbf{x}\_{ik})$ : 데이터 $\mathbf{x}_i$ 의 $k$ 번째 클래스 예측 결과값

이제 위 수식이 어떤 다른 식과 매우 유사함을 보이고자 합니다. 그렇게 하기 위해서는 확률분포의 거리를 측정하는 방법과 엔트로피에 대한 개념을 이해하고 있어야 합니다. 바로 아래에서 이어서 설명하며 위의 수식과 함께 참고해서 지켜보면 좋습니다.

<br>

# 확률분포의 거리

MLE로 추정하는 많은 학습모델 방법론은 확률분포의 거리를 최적화하는 것과 굉장히 밀접하게 연관이 되어 있습니다. 기계학습에서 사용되는 손실함수들은 모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 통해 학습하도록 유도됩니다.

데이터 공간에 2개의 확률분포 $P(x), Q(x)$ 가 있을 때 두 확률분포 사이의 거리를 계산할 때, 저희는 다음과 같은 함수를 사용해 볼 수 있습니다. 이중에서 저희가 사용해 볼 것은 `쿨백 라이블러 발산(KL-Divergence)` 입니다.

- 총변동거리
- 쿨백-라이블러 발산
- 바슈타인 거리

<br>

## 🐬 쿨백-라이블러 발산

> 쿨백-라이블러 발산(Kullback–Leibler divergence, KLD)은 두 확률분포의 차이를 계산하는 데에 사용하는 함수로, 어떤 이상적인 분포에 대해, 그 분포를 근사하는 다른 분포를 사용해 샘플링을 한다면 발생할 수 있는 정보 엔트로피 차이를 계산한다. - wikipedia

쿨백-라이블러 발산은 간단히 말해 두 확률분포가 얼마나 차이가 있는지 측정하는 방법론입니다. 각 확률변수에 대해서 다음과 같이 수식을 작성됩니다.

- 이산확률변수

$$ \mathbb{KL}(P\,\vert\vert\,Q)=\sum_{x\in \mathcal{X}}P(\mathbf{x})\log\left(\frac{P(\mathbf{x})}{Q(\mathbf{x})}\right) $$

- 연속확률변수

$$ \mathbb{KL}(P\,\vert\vert\,Q)= \int_{\mathcal{X}}P(\mathbf{x})\log\left(\frac{P(\mathbf{x})}{Q(\mathbf{x})}\right)\text{d}\mathbf{x} $$

이산확률변수의 쿨백-라이블러 발산값을 $\log$ 를 사용해서 정리하고 다시 표현해 보겠습니다. 그 결과로 신기하게 크로스 엔트로피와 엔트로피의 식이 포함된 값을 얻어낼 수 있습니다. 아래 식의 표현을 이해하기 위해서는 바로 이전 [확률 포스팅 : 기댓값](https://killerwhale0917.github.io/aimath/math-6-probability/#%EA%B8%B0%EB%8C%93%EA%B0%92)에 대한 이해가 필요합니다!! 바로 아래가 기댓값에 대한 수식이며 이를 활용해서 쿨백-라이블러 발산식에 변화를 줄 것입니다.

$$
\mathbb{E}_{\mathbf{x} \sim \mathbb{P}(\mathbf{x})}[f(\mathbf{x})] = \sum_{\mathbf{x}\in \mathcal{X}}f(\mathbf{x})\mathbb{P}(\mathbf{x})
$$

쿨백-라이블러 발산의 이산확률변수 수식에서 $\log$ 항이 기댓값에서 $f(x)$ 라고 생각을 하면 기댓값으로 풀어서 쓸 수 있습니다.

$$
\mathbb{E}_{\mathbf{x} \sim P(\mathbf{x})}\left[ \log \frac{P(\mathbf{x})}{Q(\mathbf{x})}\right] =  -\mathbb{E}_{x\sim Q(x)} \left[\log Q(x)\right] + \mathbb{E}_{x\sim P(x)}[\log P(x)]
$$

쿨백-라이블러 발산은 최종적으로 위와 같이 분해할 수 있는데, 앞의 식을 **크로스 엔트로피**, 뒤의 식을 **엔트로피**라고 부릅니다. 이는 분류 문제에서 정답 레이블을 $P$, 모델 예측을 $Q$ 라고 두면 최대가능도 추정법은 쿨백-라이블러 발산을 최소화하는 것과 같음을 보입니다.

<br>

# References

[🎨 이미지 소스](https://unsplash.com/photos/pantL8ttl_g)

[📘 베르누이 분포 - wikipedia](https://ko.wikipedia.org/wiki/%EB%B2%A0%EB%A5%B4%EB%88%84%EC%9D%B4_%EB%B6%84%ED%8F%AC)

[📘 정규분포 - wikipedia](https://ko.wikipedia.org/wiki/%EC%A0%95%EA%B7%9C_%EB%B6%84%ED%8F%AC)

[📘 라그랑주 승수법 - wikipedia](https://ko.wikipedia.org/wiki/%EB%9D%BC%EA%B7%B8%EB%9E%91%EC%A3%BC_%EC%8A%B9%EC%88%98%EB%B2%95)

[📘 laplace distribution - - wikipedia](https://en.wikipedia.org/wiki/Laplace_distribution)

[📘 감마 분포 - wikipedia](https://ko.wikipedia.org/wiki/%EA%B0%90%EB%A7%88_%EB%B6%84%ED%8F%AC)

[📘 베타 분포 - wikipedia](https://ko.wikipedia.org/wiki/%EB%B2%A0%ED%83%80_%EB%B6%84%ED%8F%AC)

[📘 라그랑주 승수법 - tistory](https://untitledtblog.tistory.com/96)




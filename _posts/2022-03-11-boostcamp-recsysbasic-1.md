---
title:  "[Recommender System] 추천시스템 Basic1"
excerpt: "유저가 원하는 것을 직접 검색해서 정보를 얻는 Pull 방식과 시스템에서 직접 추천을 해주는 Push방식의 접근에 대해서 알아보고, 추천 시스템에 해결하고자 하는 문제가 무엇인지 알아보자"

categories:
  - RecSys
tags:
  - [AI, Naver, BoostCamp, Recommender System]
toc: true
toc_sticky: true
 
date: 2022-03-11 00:00:00
last_modified_at: 2022-03-11 00:00:00
---
📌 **알립니다!**<br>
이번에 작성되는 글은 **네이버 부스트캠프 AI Tech**를 수강하며 정리하는 글입니다.<br>
여기서 존재하는 강의 자료의 출처는 네이버 부스트코스/캠프에게 있습니다.
{: .notice--info}

# 추천 시스템

추천 시스템이 왜 필요한지 추천 시스템으로 해결하고자 하는 문제가 무엇이고 어떤 정보를 입력으로 사용하는지에 대해서 알아보자

## 개요

![image](https://user-images.githubusercontent.com/91870042/157883502-77d76713-2a79-4321-a39b-dc3e566e26e5.png){: .align-center width="70%"}

현재 우리 주변에서는 실시간으로 상품의 추천이나 컨텐츠의 추천이 이루어지고 있다. 최근 많이 사용하는 OTT서비스(넷플릭스, 왓챠, 티빙)에서도 나에게 맞는 영화나 영상이 추천되곤 한다. 쿠팡과 같은 쇼핑사이트에서는 내가 관심있어하는 물품이 무엇인지 캐치해서 그 상품을 추천해주고 있다. 이처럼 추천시스템은 여러 서비스들을 **사용자의 취향에 맞추어서 추천**을 해주는 것이 중요하다.

![image](https://user-images.githubusercontent.com/91870042/157877689-4110d6a1-8bf2-4610-892b-4e838ff84eac.png){: .align-center width="70%"}

사용자가 정보를 얻는 방법에는 2가지가 있다. 하나는 **Pull** 방식이고 또 다른 하나는 **Push** 방식이다.

1. **Pull**  
**Pull은 사용자가 원하는 정보를 직접 검색해서 얻는 방법**이다. 예를 들어, 노트북을 구매하고 싶을 때 쇼핑몰에서 직접 노트북이라는 키워드를 검색해서 상품을 찾아보는 방법이다. 이 방식은 사용자가 직접 상품정보를 불러오는 것이기 때문에 Pull방식이라고 부른다.

2. **Push**  
**Push는 사용자가 시스템으로 부터 상품정보를 받게 되는 것**이다. 직접 검색을 하지 않아도 상품의 추천이 이루어지고, 그 때 사용자의 흥미 또는 의도를 고려해서 취향에 맞는 아이템을 보여준다. 말에서 알 수 있듯이 추천시스템은 이 Push 방법에 해당한다.

### 추천 시스템의 필요성

최근에 이런 추천시스템이 왜 중요해졌고 왜 필요해졌는지 알아보기 위해서 추천시스템을 사용하지 않던 옛날의 모습을 살펴봐야 한다. 이전의 **과거에서는 사용자가 접할 수 있는 컨텐츠나 상품이 매우 제한적**이었다. TV를 보더라도 그 채널의 수가 적었고, 영화도 적었고, 백화점이나 신문도 제한적으로 있었다. 그렇기 때문에 사용자가 이미 그 정보를 다 알고 있을 수 있었다.

하지만, 최근 모습을 보면 하루가 아니라 1분 사이에도 전세계에서 너무 많은 영상들과 미디어 컨텐츠들이 쏟아져 나오고 있다. 이것이 가능해 진 것은 웹과 모바일환경의 발전덕분이었다. 이러한 환경에서 나에게 딱 맞는 상품을 검색하는것에도 시간이 오래걸리게 되었고 때로는 직접 검색하지 않아도 원하는 상품을 찾아볼 수 있기를 원하게 되었다.

![image](https://user-images.githubusercontent.com/91870042/157878141-38b19bde-a79a-40dc-a644-206acb760a3a.png){: .align-center width="70%"}

이렇게 수 많은 아이템이 나오게 되면서 **Long-Tail Phenomenon**이 발생하게 되었다. Long-Tail Phenomenon은 인기 있는 소수의 아이템많이 소비되고 그 외의 수 많은 아이템들은 비교적 적게 소비되는 경향을 말한다. 추천시스템은 이런 문제를 풀고자 했고, 이 문제를 해결한 사례를 살펴보자.

1. YouTube의 동영상 추천  
내가 주로 보는 영상과 관련된 영상을 추천해주는데, 이때 그 영상의 조회수가 낮거나 구독자수가 적어도 추천이 이루어지는 경우가 있다. 이는 Long Tail에 해당하는 영상을 추천하고 있음을 알 수 있다.

2. SNS 친구 추천  
Facebook에 올라오는 추천 친구목록은 팔로워 수가 많은 유명인이 아닌, 내가 알만한 사람들을 추천해주고 있다.

## 사용 데이터

### 유저 관련 정보

![image](https://user-images.githubusercontent.com/91870042/157882203-8c710f04-d496-49ee-a100-8b070ad2d33f.png){: .align-center width="70%"}

- **유저 프로파일링**: 추천하고자 하는 유저에 관련된 정보를 구축해서 해당 유저 또는 유저 그룹별로 추천을 진행할 수 있다.
- **식별자**: 유저의 ID, 디바이스ID, 브라우저의 쿠키를 사용해서 추천을 진행할 수 있다. 브라우저의 쿠키로는 회원가입을 하지 않은 유저도 추천을 할 수 있게 만들어준다.
- **데모그래픽 정보**: 성별, 연령, 지역, 관심사와 같은 정보를 말하며 이를 수집해서 개인화된 추천을 진행할 수 있다. 하지만, 개인정보 보호법에 의해서 수집하는데 있어서 까다로워지는 추세이다.
- **유저행동 정보**: 페이지의 방문기록, 아이템에 남긴 평점기록, 아이템 구매기록의 피드백 정보를 말한다.

### 아이템 관련 정보

아이템에 대한 정보를 살펴보기에 앞서서 추천하고자 하는 아이템의 종류를 분류해보면 다음과 같이 나타낼 수 있다.

- **포털**: 뉴스, 블로그, 웹툰 등 컨텐츠
- **광고**: 광고 소재, 상품
- **미디어**: 영화, 음악, 동영상

위의 아이템에서 각 아이템에 대한 추가적인 정보를 확인해볼 수 있다. 먼저 각 아이템은 각 아이템에 대한 고유한 ID를 부여할 수 있다. 그 다음에 각 아이템별로 부여된 추가적 속성과 같은 메타데이터를 확인해보자

- 영화: 영화장르, 출연 배우, 감독, 소개글, 개봉년도
- 상품: 카테고리, 브랜드, 출시일, 상품이미지
- 음악: 아티스트, 작곡가, 장르, 음악 신호

### 유저-아이템 상호작용 정보

유저-아이템 상호작용 정보는 **유저가 아이템을 소비하고 평가하는 전체적인 정보**를 말한다. 쇼핑몰에서 특정 물품을 구매하고 클릭하는 행동들이 이 상호작용 정보에 해당한다. 이는 추천시스템을 학습하는 데이터로서 활용될 만한 충분한 가치가 있다.

이 상호작용 정보는 갖는 특성에 따라서 2가지로 분류해볼 수 있다.

1. **Explicit Feedback**  
    유저가 **"직접"** 아이템에 대해 평가한 정보를 의미한다. 예로, 영화를 본 후에 평점을 남기는 것과 같은 정보가 있다.

2. **Implicit Feedback**  
    유저가 아이템에 대한 평가를 한 것은 아니지만, 유저의 행동을 통해서 어떤 성향을 갖는지 파악하는 것을 말한다. 아이템을 구매하는 행위도 포함되고, 특정 영상을 몇 분 이상 시청하는 것도 포함된다.

모든 사용자가 모든 데이터에 대해서 평가를 남기는 것은 아니기 때문에 **Implicit Feedback의 양이 Explicit Feedback의 양보다 압도적으로 많다**. 그렇기에 Implicit Feedback정보를 잘 사용하는 것도 중요하다.

## 문제 정의

추천시스템이 결국 해결하고자 하는 것은 특정 유저에게 맞는 적합한 아이템을 추천하고 반대로 특정 아이템에 맞는 적합한 유저를 추천하는 것을 말한다. 이 추천을 하기 위해서는 유저-아이템 상호작용을 평가할 점수(Score)가 필요하고 점수를 어떻게 측정할지 알아봐야 한다.

추천은 해결하고자 하는 문제에 따라서 2가지로 나누어 생각해볼 수 있다.

1. **랭킹(Ranking)**  
랭킹문제는 유저에게 적합한 아이템 Top K개를 추천하는 것을 말한다. Top K개를 선정하기 위해서는 각 아이템별로 점수를 매겨야 하지만, 이 점수는 절대적일 필요는 없다. 마지막으로 정렬해서 상위 K개만 보여줄 것이기 때문에 상대적이어도 괜찮다.  
평가를 위한 지표에는 `Precision@K` `Recall@K` `MAP@K` `NDCG@K` 가 있다.

2. **예측(Prediction)**  
예측문제는 유저가 아이템에게 매길 평점(선호도)를 정확하게 예측하는 문제를 말한다. 평점 뿐만아니라 클릭이나 구매를 하는 것도 여기에 해당된다. 주로 유저-아이템 행렬(matrix)를 채우는 문제이다.  
평가를 위한 지표에는 `MAE`, `RMSE`, `AUC`가 있다.

## 추천시스템을 적용한 사례

- 넷플릭스 : 맞춤화된 영상 컨텐츠 추천  
![image](https://user-images.githubusercontent.com/91870042/157882852-23c6b76e-bfb1-4c34-ab23-ddc1c430cdf6.png){: .align-center width="40%"}

- 쿠팡 : 관심있는 상품 추천  
![image](https://user-images.githubusercontent.com/91870042/157882529-e6efbe38-3ac9-42c1-aaef-c97844240b02.png){: .align-center width="40%"}

- Google Ads(광고) : 개인화된 광고 추천  
![image](https://user-images.githubusercontent.com/91870042/157882589-284c7174-fb7c-4709-ae96-e312b40a7460.png){: .align-center width="40%"}

<br>

# 추천시스템 평가지표

## 개요

우리가 만든 추천시스템이나 추천모델의 성능을 평가할 수 있는 방법에 대해서 알아보자

### 비즈니스/서비스 관점

추천시스템이 비즈니스와 서비스에 얼마나 도움이 되었는지를 평가자료로 사용할 수 있다. 그 측정 방법에는 매출에 얼마나 증가했는지, 페이지를 얼마나 많이 보았는지 (Page View), 노출대비 클릭율(**CTR**)이 얼마나 상승했는지 확인해보면 된다.

### 품질 관점

- **연관성**(Relevance) : 추천된 아이템이 유저에게 관련이 있는 상품인지 평가
- **다양성**(Diversity) : 추천된 Top-K 개의 아이템이 얼마나 다양한 아이템이 존재하는지 평가
- **새로움**(Novelty) : 얼마나 새로운 아이템이 추천되고 있는지 평가
- **참신함**(Serendipity) : 유저가 기대하지 못한 뜻밖의 아이템이 추천되고 있는지 평가

## Offline Test

생성한 추천모델을 검증하기 위해서 가장 먼저 수행되는 테스트이다. 유저로부터 **수집한 데이터를 train, valid, test 데이터셋으로 나누어 모델의 성능을 객관적인 지표로 평가**하는 것이다. 보통 offline test에서 좋은 성능을 보인 모델을 Online 서빙에 투입하지만, 실제 서비스에서는 다른 양상을 보이기도 한다.

![image](https://user-images.githubusercontent.com/91870042/158001922-913825f4-d9d8-46f3-9e1f-178673acd2db.png){: .align-center}

그 중에 하나가 **Serving Bias**가 존재하기 때문이다. Serving Bias는 온라인에서 서빙하는 과정에서 발생될 수 있는 새로운 로그가 다시 학습에 사용되어서 모델이 개선되는 것을 말한다.

이 모델을 평가하기 위한 지표를 설정해야 하는데 이 성능지표는 앞서서 살펴본 랭킹문제, 예측문제에 따라서 그 방법이 달라진다.

- 랭킹문제: `Precision@K`, `Recall@K`, `MAP@K`, `NDCG@K`, `HitRate`
- 예측문제: `RMSE`, `MAE`

### Precision@K, Recall@K

**Precision@K**는 우리가 추천한 K개의 아이템 중에서 실제로 유저가 관심을 보인 아이템의 비율을 말한다. 우리가 얼마나 정확도 있게 추천을 했는지 알아볼 수 있다.

**Recall@K**는 유저가 관심있어한 아이템 중에서 우리가 추천한 비율을 말한다. 얼마나 유저의 성향을 파악해서 추천을 잘 했는지 알아볼 수 있다.

예시로 한 번 살펴보자. 우리가 추천한 아이템의 수 K를 5라고 했을 때, 유저가 관심있어한 아이템이 2개이고, 유저가 관심있어한 아이템의 전체 개수를 4개라고 한다면 다음과 같이 계산할 수 있다.

- Precision@5 = $$\frac{2}{5} = 0.4$$
- Recall@5 = $$\frac{2}{4} = 0.5$$

### AP@K, MAP@K

**AP@K**(Average Precision)은 Precision@1부터 Precision@K까지의 평균값을 의미한다. @1부터 더해서 평균을 내기 때문에 높은 순위에 있는 아이템을 추천할 수록 점수가 증가한다. 다시말해 **추천한 아이템 K개의 순서도 점수에 포함**이 된다는 의미이다. AP@K의 수식은 다음과 같다.

$$ AP@K=\frac{1}{m}\sum_{i=1}^{K}\text{Precision}@i \times rel(i) $$

- $$m$$ : 추천된 상품 중 실제로 사용자가 만족한 개수
- $$rel(i)$$ : $$i$$ 번째 상품이 실제로 사용자가 만족을 했는지 여부

**MAP@K**(Mean Avereage Precision)은 모든 유저에 대한 AP@K의 평균값을 말한다.

$$ MAP@K=\frac{1}{|U|}\sum_{u=1}^{|U|}(AP@K)_u $$

### NDCG@K

**NDCG@K**(Normal Discounted Cumulative Gain)은 추천시스템에서 가장 많이 사용되는 지표 중 하나로서 원래는 검색에서 등장한 평가지표이다. Precion@K, MAP@K와 마찬가지로 상위 K개의 아이템을 만들어서 비교를 진행한다. MAP@K처럼 상위 K개의 아이템에 대해서 더하는 연산이 존재하기 때문에 추천되는 아이템의 순서도 평가에 반영이 된다.

MAP@K에서 $$rel$$ 값을 사용할 때는 이진 값(0 또는 1)만 사용했던 것에 비해 그 값을 실수로 사용하기 때문에 유저에게 얼마나 더 관련있는 아이템을 상위로 노출시키는지 알 수 있다. 이제 NDCG의 연산이 어떻게 이루어지는지 알아보자.

- Cumulative Gain(CG): 상위 K개의 아이템에 대한 관련도를 합한 값이다.

$$ CG_K = \sum_{i=1}^{K}rel_i$$

- Discounted Cumulative Gain(DCG): 추천된 아이템의 순서에 따라서 Cumulative Gain값을 Discount한다.

$$ DCG_K = \sum_{i=1}^{K}\frac{rel_i}{log_2(i+1)} $$

- Ideal Discounted Cumulative Gain(IDCG): 이상적인 추천이 일어났을 때의 DCG값으로 가능한 DCG값 들중 가장 큰 값과 같다.

$$ IDCG = \sum_{i=1}^{K}\frac{rel_i^{opt}}{log_2(i+1)} $$

- Normalized Discounted Cumulative Gain(NDCG): 추천 결과에 따라 구해진 DCG를 IDCG로 나눈 값을 말한다. 얼마나 이상적으로 추천이 이루어졌는지 확인해볼 수 있다.

$$ NDCG = \frac{DCG}{IDCG} $$

## Online Test

Online Test는 Offline Test에서 검증된 가설이나 모델을 이용해서 실제 서비스에 적용시켜서 그 추천 결과를 서빙하는 단계이다. Online A/B Test로 진행되고 추천시스템 변경 전후의 성능을 비교하는 것이 아니라, **대조군과 실험군을 두어서 동시에 성능을 평가**한다. 이때 중요한 것은 대조군과 실험군의 환경은 최대한 동일하게 맞춰줘야 한다.

![image](https://user-images.githubusercontent.com/91870042/158005511-28249301-68aa-41b7-bc91-b777b6752cf4.png){: .align-center width="70%"}

실제 현업에서는 의사결정에 사용되는 지표는 모델의 성능이 아니라 **매출 또는 CTR등의 비즈니스 / 서비스 지표를 사용**한다.

<br/>

# 인기도 기반 추천

## 개요

인기도 기반 추천은 말 그대로 상품들 중에서 가장 인기있는 상품을 추천하는 것이다. 그렇다면 인기있다는 것은 어떻게 기준을 삼아서 분류할 수 있을지 생각해보아야 한다. 인기도의 척도에는 조회수, 평균평점, 리뷰의 개수, 좋아요와 싫어요의 개수 등 다양한 속성을 사용해볼 수 있다.

- **Most Popular** : 조회수가 가장 많은 아이템을 추천하는 것으로, 다른 유저들도 관심을 갖는 아이템을 추천하는 것이다. 보통 뉴스기사 추천을 예로 생각해볼 수 있다. 사람들은 다른 사람들도 많이 찾아본 이슈를 찾아보길 원한다.
- **Highly Rated** : 평균 평점이 가장 높은 아이템을 추천하는 것으로, 맛집 추천이 이에 해당한다. 평점이 높은 맛집일수록 맛있는 음식을 제공하는 음식점으로 생각해볼 수 있다.

## Most Popular

조회수가 많은 아이템을 추천하거나 좋아요가 가장 많은 아이템을 추천하는 것이 여기에 해당된다. 하지만 단순히 조회수가 많은 아이템만을 기준으로 삼아서 추천을 진행하면, 너무 오래되었지만 조회수가 높은 것들이 계속 추천이 될 것이다. 그렇기 때문에 얼마나 오래된 것인지 판단하는 age 속성과 함께 계산해야 한다.

$$ \text{score} = f(\text{popularity}, \text{age}) = (\text{upvote} - \text{downvote}) - \text{time_elapsed} = \text{page_view} - \text{time_elapsed}$$

하지만, 위의 식에서 <u>pageview가 너무 빠르게 늘어나서 아주 큰 값을 가지게 된다면 시간이 아무리 지나도 상위권에 해당 아이템이 뜨는 문제가 발생</u>한다.

### Hacker News Formula

Hacker News에서는 많은 사람들이 본 뉴스를 추천하되, 최신의 정보를 포함하도록 설정하였다. 시간이 지날 수록 age값을 증가시켜서 전체적인 score 값을 감소시키는 방법을 사용하였다. 또한 시간에 따라 줄어드는 score를 조정하기 위해서 gravity라는 상수를 사용하였다.

$$ score=\frac{pageviews-1}{(age+2)^{gravity=1.8}} $$

### Reddit Formuula

Reddit에서는 위의 Hacket News처럼 score값을 분모로 나누어서 **감점시키는 방법을 사용하지는 않았다**. 반대로 **최근에 포스팅된 글에 더 높은 점수를 부여**해서 상위에 추천될수 있도록 만들었따.

$$ score=log_{10}(ups-downs)+\frac{sign(ups-downs)\cdot seconds}{45000} $$ 

위에서 첫 번째 term은 popularity, 두 번째 term은 글이 포스팅된 절대시간을 의미한다. 나중에 게시된 포스팅일수록 절대시간이 크기 때문에 더 높은 score를 갖도록 하였다.

하나 더 눈여겨 볼 점은 좋아요와 싫어요 수에 log를 씌운 것이다. 그 이유는 한 번 아이템이 상단에 올라가게 되면 추천수가 급증하기 때문에 그런 문제점을 해결하기 위해 점점 증가폭이 적어지는 log를 사용했다.

## Highly Rated

높은 평점을 받은 아이템을 추천하는 방법이지만, 생각해 보아야 할 것은 높은 평점이라고 반드시 그 점수를 신뢰할 수 있다는 보장은 없다. 예를 들어서 평가의 개수가 1000개인데 4.7점인 것과 평가의 개수가 1개인데 4.8점인 것을 비교하는 문제와 동일하다. 그렇기 때문에 평가의 개수도 같이 고려를 진행해야 한다.

$$ \text{score} = f(\text{rating}, \text{# of ratings}) $$

### Stream Rating Formula

전체 평점은 모든 평점에 대한 평균값을 사용하되, 그 개수에 따라서 보정을 하는 방법이다. 수식은 다음과 같다.

$$ \text{avg_rating}=\frac{\text{# of positive reviews}}{\text{# of reviews}} $$

$$ \text{score} = \text{avg_rating} - (\text{avg_rating}-0.5)\cdot 2^{-log(\text{# of reviews})} $$ 

위의 수식은 review개수가 너무 적을 때 score값이 0.5보다 작다면 더 높게 보정을 하고, score의 값이 너무 크다면 0.5보다 낮게 보정을 진행해주는 수식이다. review의 개수가 정말 많다면 score값은 전체 에 대한 평균값과 거의 유사해진다. 가까워질 수 있는 것은 $$ 2^{-\log} $$ 식 덕분인데 매우 커지면 0에 가까워지기 때문이다.

예로, 영화평점이 1점~5점으로 부여될 수 있다면 그 평균값인 3점으로 균형을 맞추어줄 수 있다.

$$ \text{score} = \text{avg_rating} - (\text{avg_rating}-3.0)\cdot 2^{-log(\text{# of reviews})} $$ 


---
title:  "[PyTorch] Hyperparameter Tuning"
excerpt: "PyTorchì—ì„œ ì´ˆë§¤ê°œë³€ìˆ˜ë¥¼ ìµœì ìœ¼ë¡œ ì„¤ì •í•˜ë„ë¡ ë„ì™€ì£¼ëŠ” Ray Tune í”„ë ˆì„ì›Œí¬ì™€ ê¸°ë³¸ì ì¸ Grid & Random, Bayesian parameter search ë°©ë²•ë¡ ì— ëŒ€í•œ ì†Œê°œ"

categories:
  - pytorch
tags:
  - [AI, Naver, BoostCamp, Python, Pytorch]
toc: true
toc_sticky: true
 
date: 2022-01-27 01:00:00
last_modified_at: 2022-01-27 01:00:00
---
ğŸ“Œ **ì•Œë¦½ë‹ˆë‹¤!**<br>
ì´ë²ˆì— ì‘ì„±ë˜ëŠ” ê¸€ì€ **ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech**ë¥¼ ìˆ˜ê°•í•˜ë©° ì •ë¦¬í•˜ëŠ” ê¸€ì…ë‹ˆë‹¤.<br>
ì—¬ê¸°ì„œ ì¡´ì¬í•˜ëŠ” ê°•ì˜ ìë£Œì˜ ì¶œì²˜ëŠ” ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ì½”ìŠ¤/ìº í”„ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
{: .notice--info}

ì‚¬ëŒì´ ì§ì ‘ ì„¤ì •í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ì¸ **Hyper parameter**ë¥¼ ì–´ë–»ê²Œ ì„¤ì •í•´ì•¼ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆì„ì§€, ì–´ë–»ê²Œ ì¡°ì •í• ì§€ì— ëŒ€í•´ Ray Tuneëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì•Œì•„ë³¸ë‹¤.

# ì •í™•ë„ë¥¼ ë†’ì´ëŠ” ë°©ë²•

ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ì„œëŠ” í¬ê²Œ 3ê°€ì§€ ë°©ë²•ì´ ì¡´ì¬í•œë‹¤.

1. ëª¨ë¸ì„ ë°”ê¾¸ê¸°
2. ë°ì´í„°ì˜ ì¶”ê°€ / ë³€ê²½
3. Hyperparameter Tuning

ì¼ë°˜ì ìœ¼ë¡œ ìœ„ì—ì„œ ê°€ì¥ íš¨ê³¼ì ìœ¼ë¡œ ì •í™•ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆëŠ” ë°©ë²•ì€ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë³€ê²½í•˜ëŠ” ì‘ì—…ì´ë‹¤. ê·¸ ë‹¤ìŒìœ¼ë¡œ íš¨ê³¼ì ì¸ ê²ƒì€ ëª¨ë¸ì´ê³  ë§ˆì§€ë§‰ìœ¼ë¡œ ë§ˆì§€ë§‰ 0.01% ê¹Œì§€ ì˜¬ë¦¬ê¸° ìœ„í•´ì„œ Hyper parameter Tuningì„ ì‚¬ìš©í•œë‹¤.

> ë°ì´í„° > ëª¨ë¸ > Hyper Parameter

ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ë¬¸ì œì— ëŒ€í•´ì„œ ê±°ì˜ ê³ ì •ì´ ë˜ì–´ì„œ ì‚¬ìš©ë˜ê¸° ë•Œë¬¸ì— ì¼ë°˜ì ìœ¼ë¡œ ì¢‹ì€ ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë‹¤.

<br>

# Hyperparameter Tuning

ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ì§€ ì•ŠëŠ” ê°’ì„ ì‚¬ëŒì´ ì§ì ‘ ì§€ì •í•˜ëŠ” ê²ƒì„ hyper parameterë¼ê³  í•œë‹¤. ëŒ€í‘œì ìœ¼ë¡œ í•™ìŠµë¥ (learning rate), ëª¨ë¸ì˜ í¬ê¸°, optimizerë“±ì´ ìˆë‹¤. ì˜ˆì „ì—ëŠ” Hyper parameterë¥¼ ìˆ˜ì •í•˜ì—¬ ì„±ëŠ¥ì´ í¬ê²Œ ì¢Œìš°ë˜ì—ˆì§€ë§Œ ìµœê·¼ì—ëŠ” ë§ì€ ë°ì´í„°ë¡œ ì´ê²ƒì„ ê·¹ë³µí•´ ë‚˜ê°€ê³  ìˆë‹¤.

---

![image](https://user-images.githubusercontent.com/91870042/151476866-85e7c020-656d-46e9-8a32-ba53c757f4c7.png){: .align-center width="70%"}

## Grid Sampling
**ê·¸ë¦¬ë“œ ìƒ˜í”Œë§**ì€ ë¶ˆì—°ì† hyper parameterë¥¼ ì§€ì›í•˜ë©° ì‘ë™ì›ë¦¬ëŠ” hyper parameter ê°ê°ì— ì ìš©í•  ê°’ë“¤ì„ ì •í•´ë‘ê³  ëª¨ë“  ì¡°í•©ì— ëŒ€í•´ì„œ ì–´ë– í•œ ì„±ëŠ¥ì´ ë‚˜ì˜¤ëŠ”ì§€ ê¸°ë¡í•œ í›„, ìµœê³ ì˜ ì„±ëŠ¥ì„ ë‚´ëŠ” hypter parameterë¡œ ì„¤ì •í•˜ëŠ” ë°©ë²•ì´ë‹¤.

ì´ ê·¸ë¦¬ë“œ ìƒ˜í”Œë§ì€ ê°„ë‹¨í•˜ì§€ë§Œ, hyper parameterì˜ ê°œìˆ˜ê°€ ë§ì•„ì§€ê²Œ ë˜ë©´ í•„ìš”í•œ ì—°ì‚°íšŸìˆ˜ê°€ ë§¤ìš° ë§ì•„ì§€ê²Œ ë˜ì–´ tuningí•˜ëŠ”ë° ìˆì–´ì„œ ì–´ë ¤ì›€ì„ ê²ªì„ ìˆ˜ ìˆë‹¤.

## Random Sampling
**ëœë¤ ìƒ˜í”Œë§**ì€ hyper parameterë¡œ ì„¤ì •í•  ê°’ì„ ë¯¸ë¦¬ ì •í•´ë‘ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê° ë§¤ê°œë³€ìˆ˜ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœì†Ÿê°’ê³¼ ìµœëŒ“ê°’ì„ ì§€ì •í•œ í›„, ê·¸ ë‚´ì—ì„œ ë¬´ì‘ìœ„ë¡œ ì¶”ì¶œí•˜ì—¬ ì„±ëŠ¥ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ë¦¬ë“œ ìƒ˜í”Œë§ê³¼ ìœ ì‚¬í•œ êµ¬ì¡°ë¥¼ ê°–ì§€ë§Œ, ë‹¨ì§€ ë¬´ì‘ìœ„ë¡œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¶”ì¶œí•˜ì—¬ ì‹œë„í•œë‹¤ëŠ” ê²ƒì´ ì°¨ì´ì ì„ ê°–ëŠ”ë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ ì‹œê°„ëŒ€ë¹„ ì„±ëŠ¥ì€ ëœë¤ ìƒ˜í”Œë§ì´ ë” ì¢‹ë‹¤ê³  í‰ê°€ë˜ê³  ìˆë‹¤.

## Bayesian Sampling
**Bayesian ìƒ˜í”Œë§**ì€ Bayesianìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•œë‹¤. í•µì‹¬ì€ ì´ì „ ìƒ˜í”Œì—ì„œ ìˆ˜í–‰í•œ ë°©ì‹ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒ˜í”Œì„ ì„ íƒí•˜ì—¬ ìƒˆë¡œ ì„ íƒí•œ ìƒ˜í”Œì´ ê¸°ë³¸ metricì„ í–¥ìƒ ì‹œí‚¤ë„ë¡ í•œë‹¤. ì´ëŸ° ì•„ì´ë””ì–´ë¥¼ `ë² ì´ì¦ˆì´ë¡ `ê³¼ `ê°€ìš°ì‹œì•ˆ í”„ë¡œì„¸ìŠ¤`ì— ì ìš©ì‹œì¼œì„œ ë§Œë“  ê²ƒì´ Bayesian Samplingì´ë‹¤.

<br>

# Ray
multi-node, multi processingì„ ì§€ì›í•˜ëŠ” ëª¨ë“ˆë¡œì„œ ML/DLì˜ ë³‘ë ¬ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œ ê°œë°œì´ ë˜ì—ˆë‹¤. í˜„ì¬ ë¶„ì‚°ë³‘ë ¬ ML/DLì˜ í‘œì¤€ì´ë©° ìš°ë¦¬ê°€ ì›í•˜ëŠ” hyperparameter searchë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ëª¨ë“ˆì„ ì œê³µí•œë‹¤.

```py
from ray import tune
from ray.tune import CLIReporter
from ray.tune.schedulers import ASHAScheduler

data_dir = os.path.abspath("./data")
load_data(data_dir)

# Configì— search spaceë¥¼ ì§€ì •í•œë‹¤.
config = {
    'l1': tune.sample_from(lambda _: 2 ** np.random.randint(2, 9))
    'l2': tune.sample_from(lambda _: 2 ** np.random.randint(2, 9))
    'lr': tune.loguniform(1e-4, 1e-1),
    'batch_size': tune.choice([2, 4, 8, 16])
}

# í•™ìŠµ ìŠ¤ì¼€ì¤„ë§ ì•Œê³ ë¦¬ì¦˜ ì„¤ì •
scheduler = ASHAScheduler(
        metric="loss",
        mode="min",
        max_t=max_num_epochs,
        grace_period=1,
        reduction_factor=2)

# ê²°ê³¼ ì¶œë ¥ ì–‘ì‹ ì§€ì •
reporter = CLIReporter(
        metric_columns=["loss", "accuracy", "training_iteration"])

# ë³‘ë ¬ ì²˜ë¦¬ ì–‘ì‹ìœ¼ë¡œ í•™ìŠµ ì‹¤í–‰
# train_cifar -> í•™ìŠµí•˜ëŠ” ê³¼ì •ì´ "í•¨ìˆ˜"ë¡œ êµ¬í˜„ì´ ë˜ì–´ ìˆì–´ì•¼ í•œë‹¤.
result = tune.run(
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
        config=config,
        num_samples=num_samples,
        scheduler=scheduler,
        progress_reporter=reporter)

# ìµœì ì˜ ì„±ëŠ¥ì„ ë‚´ëŠ” ë§¤ê°œë³€ìˆ˜, ì˜¤ì°¨, ì •í™•ë„ ì¶œë ¥
best_trial = result.get_best_trial("loss", "min", "last")
    print("Best trial config: {}".format(best_trial.config))
    print("Best trial final validation loss: {}".format(
        best_trial.last_result["loss"]))
    print("Best trial final validation accuracy: {}".format(
        best_trial.last_result["accuracy"]))
```

<br>

# References

[ğŸ“˜ Hyperparameter optimization](https://blog.naver.com/PostView.naver?blogId=cjh226&logNo=221408767297&categoryNo=16&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView)

[ğŸ“˜ 4. ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ : í™•ë¥ ë¡ ê³¼ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ(Naive Bayes)ë¶„ë¥˜](https://nittaku.tistory.com/283)

[ğŸ“˜ Azure Machine Learningì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ íŠœë‹í•˜ëŠ” í•˜ì´í¼ ë§¤ê°œ ë³€ìˆ˜](https://docs.microsoft.com/ko-kr/azure/machine-learning/how-to-tune-hyperparameters)


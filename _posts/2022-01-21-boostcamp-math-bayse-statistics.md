---
title:  "[AI Math] 조건부확률과 베이즈정리"
excerpt: "조건부확률에서 이어지는 개념인 베이즈 정리와 인과관계 추론"

categories:
  - boostcamp
tags:
  - [AI, Naver, BoostCamp, Math]
toc: true
toc_sticky: true
 
date: 2022-01-20 02:00:00
last_modified_at: 2022-01-20 02:00:00
---
📌 **알립니다!**<br>
이번에 작성되는 글은 **네이버 부스트캠프 AI Tech**를 수강하며 정리하는 글입니다.<br>
여기서 존재하는 강의 자료의 출처는 네이버 부스트코스/캠프에게 있습니다.
{: .notice--info}

# 조건부 확률
베이즈 통계학을 이해하기 위해서는 먼저 조건부확률의 개념을 이해해야 한다.

$$ (P(A\bigcap B) = P(B)P(A\|B) $$


위의 식에서 조건부 확률 \\(P(A\|B)\\)는 사건 \\(B\\)가 일어난 상황에서 사건 \\(A\\)가 발생할 확률을 의미한다. 다시 말해 \\(P(B)\\)를 좌항으로 넘기면, 사건\\(B\\)가 일어난 상황에서, 사건\\(A\\)와 사건\\(B\\)가 일어난 상황을 말한다.

<br>

# 베이즈 정리
베이즈 정리는 위에서 말한, 조건부 확률을 이용하여 `정보를 갱신하는 방법`에 대해서 알려준다. 정보를 갱신하는 것은 아래에서 다시 설명하지만, \\(A\\)라는 새로운 정보가 주어졌을 때, 기존의 계산된 정보 \\(P(B)\\)로 부터 \\(P(B|A)\\)를 계산하는 방법을 제공해준다.

아래의 식은 위에서 정의한 조건부확률 식을 분자에 대입하여 얻을 수 있다.

$$ P(B|A) = \frac{P(A\bigcap B)}{P(A)} = P(B)\frac{P(A|B)}{P(A)} $$

위의 식에서 기호만 조금 변경하여서 다른 말로 설명하면 다음과 같다.

$$ P(\theta | D) = P(\theta)\frac{P(D|\theta)}{P(D)} $$

1. \\(D\\): 관찰하는 데이터
2. \\(\theta\\): 가설, 모델링하는 이벤트, 모델에서 계산하고 싶은 parameter(모수)

- `사후확률(posterior)`: 데이터가 주어져있을 때, 가설이 성립할 확률을 말한다. 사후확률이라고 부르는 것은, 데이터를 먼저 관찰하고 나서 확률을 계산하기 때문이다.
- `사전확률(prior)`: 데이터가 주어지지 않은 상황에서, 가설\\(theta\\)의 주어진 확률이다.
- `가능도(likelihood)`: 현재 주어진 가설에서 이 데이터가 관찰될 확률이다.
- `Evidence`: 데이터 자체의 분포를 말한다.

## 예제
COVID-99의 발병률이 10%로 알려져 있다. COVID-99에 실제로 걸렸을 때 검진될 확률은 99%, 실제로 걸리지 않았을 때 오검진 될 확률이 1%라고 할 때, 어떤 사람이 질병에 걸렸다고 검진결과가 나왔을때 정말로 COVID-99에 감염되었을 확률은?

이 문제는 **사전확률, 민감도(Recall), 오탐율(Ralse alarm)을 가지고 정밀도(Precision)을 계산하는 문제**이다.

위의 그림에서 **\\(\theta\\)를 COVID-99 발병사건으로 정의**하고, **\\(D\\)를 테스트 결과라고 정의**해보자. 그러면 다음과 같이 표현할 수 있다.

- \\(P(\theta)=0.1\\): COVID-99의 발병률
- \\(P(D\|\theta)=0.99\\): 실제로 걸렸을 때, 검진될 확률
- \\(P(D\|\neg \theta)=0.99\\): 실제로 걸리지 않았을 때, 오검진될 확률

위의 정보들을 이용해서 Evidence값 즉, 데이터의 분포를 구해야한다. 여기서 말하는 데이터의 분포는 실제로 양성인 확률을 말한다.

> Evidence = COVID-99에 양성판정일 때, 실제 양성인 경우 + 음성판정일 때, 실제로 양성인 경우

$$ P(D) = \sum_\theta P(D|\theta)P(\theta) = 0.99\times 0.1 + 0.01 \times 0.9 = 0.108 $$

$$ P(\theta | D) = 0.1 \times \frac{0.99}{0.108} \approx 0.916 $$

따라서, 실제로 양성인 경우, 양성판정을 받을 확률이 91.6%임을 말하고 이렇게 높은 정확도가 나올 수 있었던 것은 오탐률이 1%로 낮았기 때문이다. 

하지만, 이번에는 오탐률을 10%로 높여서 계산해보자. 그렇다면 위에서 변경되는 식은 다음과 같다.

$$ P(D|\neg \theta) = 0.1 $$

$$ P(D) = \sum_\theta P(D|\theta)P(\theta) = 0.99\times 0.1 + 0.1 \times 0.9 = 0.189 $$

$$ P(\theta | D) = 0.1 \times \frac{0.99}{0.189} \approx 0.524 $$

위와 같이, 오탐률을 10%로 높인 결과 그 정확도는 52.4% 로 크게 감소하였다.

## 조건부 확률의 시각화
![image](https://user-images.githubusercontent.com/91870042/145146703-1ba84253-0369-492b-a4dd-6e6a74691daf.png){: .align-center}

- True Positive: 양성판정일 때, 실제로 감염된 경우
- True Negative: 음성판정일 때, 실제로 감염되지 않은 경우
- False Positive: 양성판정일 때, 감염되지 않은 경우
- False Negative: 음성판정일 때, 실제로 감염된 경우

우리는 위의 분류에서 False Positive를 `1종 오류`, False Negative를 `2종 오류`라고 부른다. 따라서 위에서 1종오류 또는 2종오류를 줄여야 하는데, 어떤 것을 줄여야 할지 판단해야한다. 이는 문제에 따라서 달라지게 된다.

예를 들어, 어떤 병원에서 암에 대한 판정을 한다고 하자. 1종 오류는 암이 있다고 판정했는데, 실제로 없는 경우이고, 2종 오류는 암이 없다고 판정했는데 실제로 있는 경우를 말한다. 이 경우, 2종 오류에 대한 위험부담이 더 크므로 2종 오류를 줄여야 한다.

![image](https://user-images.githubusercontent.com/91870042/150640470-683d22fd-42b0-4172-b295-d885c0545c46.png){: .align-center}

하지만, 정밀도를 구하는 \\(P(\theta \| D)\\) 이 식은 <u>1종 오류를 줄여야 분모에 해당하는 값이 작아지기 때문에 정밀도가 올라간다.</u>


## 베이즈 정리를 통한 정보의 갱신
베이즈 정리를 통하여 새로운 데이터가 들어왔을 때, 앞서 계산한 **사후확률을 사전확률로 사용**하여 갱신된 사후확률을 계산할 수 있다. 이는 기계학습에서 데이터를 새로 관측할 때마다 사후확률을 계산하여 어떠한 모델의 정확도를 높이는 것이 가능해지게 만든다.

위에서 살펴본 `COVID-99`의 예시에서 이 정보의 갱신을 이용해, COVID-99 판정을 받은 사람이 2번째 검진에서도 양성이 나올 확률을 계산하는 것이 가능하다.

사후확률로 계산된 52.4%의 확률을 다시 사전확률 \\(P(\theta)\\)로 계산하면 다음과 같은 식이 나온다.

\begin{aligned}
P(D^{\*}) &= P(D^{\*} \| \theta) \times P(\theta) + P(D^* \| \neg \theta) \times P(\neg \theta)\\\\\\
&= 0.99 \times 0.524 + 0.1 \times 0.476 \approx 0.566
\end{aligned}

$$ P(\theta | D^*) = 0.524 \times \frac{0.99}{0.566} \approx 0.917 $$

이는 감염된 사람이 2번째 검사에서도 양성이 나올 확률이 91.7%임을 이야기하고 3번째 검사에서도 양성이 나올 확률을 계산하면 99.1%까지 올라간다.

## 조건부 확률과 인과관계
> 조건부 확률은 유용한 통계적 해석을 제공하지만,  
> 인과관계를 추론할 때 함부로 사용해서는 안된다.

데이터가 많아져도 조건부 확률만을 가지고 인과관계를 추론하는 것은 불가능하다.

![image](https://user-images.githubusercontent.com/91870042/145147335-c00c7624-a199-4bbb-a398-35c0163ec8d3.png){: .align-center}

조건부확률만을 가지고, 예측모델을 만들었을 때, 다양한 시나리오 마다 예측정확도가 많이 차이나는 모습을 볼 수 있다. 이럴 경우, `인과관계`를 사용하여 계산하면 여러 시나리오에도 예측정확도가 크게 변하지 않는 상황을 만들 수 있다.

조건부확률에서 인과관계를 알아내기 위해서는 `중첩요인(confounding factor)`의 효과를 제거하고 원인에 해당하는 변수만의 인과관계를 계산해야한다.

![image](https://user-images.githubusercontent.com/91870042/145147547-341bb919-1fa3-4b8f-8f28-c06b6687fd1c.png){: .align-center}

### 예시1: 키와 지능의 관계
중첩요인을 제거하지 않은 상태에서, 지능지수와 키의 연관성분석을 하면 놀랍게도 둘 사이의 연관성은 있다고 나온다. (R: 지능지수, T: 키)

그 이유는 나이라는 중첩지수를 제거하지 않았기 때문이다. 나이가 많아질 수록, 키가 커지고 지능도 높아지기 때문에, 둘 사이의 인과관계가 있다고 나오는 것이다. 이렇듯 인과관계를 알아낼 때는 `중첩요인`을 제거하는 것이 중요하다.

### 예시2: 신장결석의 크기와 치료법
![image](https://user-images.githubusercontent.com/91870042/150640708-ab1b7c21-e78a-4c5c-a58c-edcfd10dfc0d.png){: .align-center}

전체적으로 봤을 때는 치료법B가 더 완치율이 높지만, 각각의 환자로부터 결과를 봤을 때는 치료법A의 완치율이 높다. 어떻게 이런일이 발생할까? 이러한 현상을 `simpson's paradox`라고 한다.

이 역설을 해결하기 위해서는 조건부 확률만을 가지고 계산해서는 안된다. 이 모델에서 **중첩효과를 제거**해야 가능하다.

신장 결석 크기에 따른 치료법의 선택을 중첩효과를 제거하는 방식에 사용해볼 수 있다. 전체적인 결과로 치료법B가 더 좋다고 나온 이유는 신장결석의 크기라는 숨겨진 변수를 전혀 고려하지 않은 상황이기 때문이다.

먼저 치료법 A에 대해 중첩요인인 **신장결석의 크기**를 제거하고 계산하는 과정을 보자. 아래서 말하는 \\(s, b\\)는 각각 `작은 신장결석`, `큰 신장결석`을 말한다.

\begin{aligned}
  P^{A}(R=1) &= \sum_{z\in \{s, b\}}P(R=1\|T=b, Z=z)P(Z=z)\\\\\\
  &=\frac{81}{87}\times \frac{(87+270)}{700} + \frac{192}{263} \times \frac{(263+80)}{700} \approx 0.8325
\end{aligned}

그다음은 치료법 B에 대해 중첩요인을 제거하고 계산하는 식이다.

\begin{aligned}
  P^{B}(R=1) &= \sum_{z\in \{s, b\}}P(R=1\|T=b, Z=z)P(Z=z)\\\\\\
  &=\frac{234}{270}\times \frac{(87+270)}{700} + \frac{55}{80} \times \frac{(263+80)}{700} \approx 0.7789
\end{aligned}

이렇게 중첩효과를 제거하고 계산을 했을 때, 치료법 A는 78%에서 83%로, 치료법B는 83%에서 77%로 나타나는 것을 볼 수 있다.

<br>

# References

[📘 위키백과: 심슨의 역설](https://ko.wikipedia.org/wiki/%EC%8B%AC%EC%8A%A8%EC%9D%98_%EC%97%AD%EC%84%A4)

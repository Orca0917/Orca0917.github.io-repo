---
title:  "[PyTorch] ëª¨ë¸ ì €ì¥, ë¶ˆëŸ¬ì˜¤ê¸°"
excerpt: "PyTorchì˜ ëª¨ë¸ì„ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ê³¼ Transfer Learningì„ í™œìš©í•œ ëª¨ë¸ì˜ í•™ìŠµ ë°©ë²•"

categories:
  - pytorch
tags:
  - [AI, Naver, BoostCamp, Python, Pytorch]
toc: true
toc_sticky: true
 
date: 2022-01-26 00:00:00
last_modified_at: 2022-01-26 00:00:00
---
ğŸ“Œ **ì•Œë¦½ë‹ˆë‹¤!**<br>
ì´ë²ˆì— ì‘ì„±ë˜ëŠ” ê¸€ì€ **ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech**ë¥¼ ìˆ˜ê°•í•˜ë©° ì •ë¦¬í•˜ëŠ” ê¸€ì…ë‹ˆë‹¤.<br>
ì—¬ê¸°ì„œ ì¡´ì¬í•˜ëŠ” ê°•ì˜ ìë£Œì˜ ì¶œì²˜ëŠ” ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ì½”ìŠ¤/ìº í”„ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
{: .notice--info}

PyTorchë¥¼ ì´ìš©í•´ì„œ ì§ì ‘ ëª¨ë¸ì„ ë§Œë“¤ì–´ì„œ í•™ìŠµì‹œí‚¨ ê²½ìš°, ì¢…ì¢… í•™ìŠµì‹œí‚¨ ëª¨ë¸ì„ ì €ì¥í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì‚¬ëŒì´ ì˜ ë§Œë“¤ì–´ë†“ì€ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ìˆ˜ì •í•´ì„œ ì“°ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì´ë²ˆì—ëŠ”, ë‚´ê°€ ë§Œë“  ëª¨ë¸ì„ ì €ì¥ì‹œí‚¤ëŠ” ë°©ë²•ê³¼ ë‹¤ë¥¸ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ ì•Œì•„ë³¸ë‹¤.

<br>

# `torch.save()`: modelì˜ ì €ì¥

`torch.save()`ë¥¼ ì´ìš©í•´ì„œ ë‚´ê°€ ìƒì„±í•œ ëª¨ë¸ì˜ í•™ìŠµ ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë©° ë‹¤ìŒ 2ê°€ì§€ë¥¼ ì €ì¥ì‹œí‚¬ ìˆ˜ ìˆë‹¤.

1. ëª¨ë¸ì˜ Architecture

    ```py
    torch.save(model, PATH)
    ```

    ëª¨ë¸ ìì²´ë¥¼ ì €ì¥í•˜ëŠ” ê²½ìš°, Pythonì˜ `pickle`ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ì˜ ëª¨ë“ˆì„ ì €ì¥í•œë‹¤. ì´ë¡œ ìƒê¸°ëŠ” ë‹¨ì ì€ ëª¨ë¸ì„ ì €ì¥í•  ë•Œ, ì‚¬ìš©í•œ íŠ¹ì • í´ë˜ìŠ¤ë‚˜ êµ¬ì¡°ì— ì–½ë§¤ì´ê²Œ ëœë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ, ë§Œë“¤ì–´ë‘” ëª¨ë¸ì„ ë‹¤ë¥¸ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©í•˜ê±°ë‚˜ ìˆ˜ì •í•˜ë©´ ì—¬ëŸ¬ê°€ì§€ ì´ìœ ë¡œ ì œëŒ€ë¡œ ë™ì‘í•˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤.

2. ëª¨ë¸ì˜ Parameter

    ```py
    torch.save(model.state_dict(), PATH) # ëª¨ë¸ì„ ì €ì¥í•  ë•Œ ê¶Œì¥ë˜ëŠ” ë°©ì‹
    ```

ìœ„ì˜ í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ì €ì¥ì‹œí‚¨ ëª¨ë¸ì˜ í™•ì¥ìëŠ” ì¼ë°˜ì ìœ¼ë¡œ `.pt`, `.pth`ë¡œ ì„¤ì •í•˜ëŠ”ë°, `.pt`ë¡œ ì €ì¥í•˜ëŠ” ê²ƒì„ ë” ì„ í˜¸í•œë‹¤. `.pth`ëŠ” íŒŒì´ì¬ì˜ í™•ì¥ìì—ë„ í¬í•¨ì´ ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— PyTorchì˜ í™•ì¥ìì„ì„ ì•Œë¦¬ëŠ” `.pt`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤.


## `state_dict()`ê°€ í•˜ëŠ” ì—­í•   
PyTorchì—ì„œ ëª¨ë¸ì€ í•™ìŠµ ê°€ëŠ¥í•œ ë³€ìˆ˜ì¸ ê°€ì¤‘ì¹˜ ë˜ëŠ” í¸í–¥ê³¼ ê°™ì€ ì •ë³´ë¥¼ ëª¨ë¸ì˜ Parameterë¡œ ì €ì¥í•˜ê³  ìˆë‹¤. ì´ ë•Œ, ê° ëª¨ë¸ì˜ ParameterëŠ” `model.parameters()`ë¡œ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë‹¤.

`state_dict`ëŠ” í•˜ë‚˜ì˜ ëª¨ë¸ì— í¬í•¨ëœ ë ˆì´ì–´ ë³„ë¡œ, ë°©ê¸ˆ ë§í•œ Parameterì™€ Buffer í…ì„œë¥¼ ë§¤í•‘í•œ Pythonì˜ ì‚¬ì „ ê°ì²´ì´ë‹¤.

```py
import torch
import torch.nn as nn

class TheModelClass(nn.Module):
    def __init__(self):
        super(TheModelClass, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=0), 
            nn.BatchNorm2d(16), 
            
            nn.ReLU(), 
            nn.MaxPool2d(kernel_size=2, stride=2) 
        )
        self.drop_out = nn.Dropout() 
        self.fc1 = nn.Linear(3 * 3 * 64, 1000) 
        self.fc2 = nn.Linear(1000, 1)
        
    def forward(self, x):
        out = self.layer1(x)
        out = out.view(out.size(0), -1)
        
        out = self.drop_out(out)
        out = self.fc1(out)
        out = self.fc2(out)
        
        return out
    
model = TheModelClass().cuda()

print("âœ” 1. Model's parameter name")
for name, params in model.named_parameters():
    print(name)

print("\nâœ” 2. Model's buffer name")
for name, buffs in model.named_buffers():
    print(name)
    
print("\nâœ” 3. Model's state_dict:")
for param_tensor in model.state_dict():
    print(param_tensor, '\t', model.state_dict()[param_tensor].size())
```
ë°”ë¡œ ìœ„ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
```text
âœ” 1. Model's parameter name
layer1.0.weight
layer1.0.bias
layer1.1.weight
layer1.1.bias
fc1.weight
fc1.bias
fc2.weight
fc2.bias

âœ” 2. Model's buffer name
layer1.1.running_mean
layer1.1.running_var
layer1.1.num_batches_tracked

âœ” 3. Model's state_dict:
layer1.0.weight 	 torch.Size([16, 3, 3, 3])
layer1.0.bias 	 torch.Size([16])
layer1.1.weight 	 torch.Size([16])
layer1.1.bias 	 torch.Size([16])
layer1.1.running_mean 	 torch.Size([16])
layer1.1.running_var 	 torch.Size([16])
layer1.1.num_batches_tracked 	 torch.Size([])
fc1.weight 	 torch.Size([1000, 576])
fc1.bias 	 torch.Size([1000])
fc2.weight 	 torch.Size([1, 1000])
fc2.bias 	 torch.Size([1])
```
í•˜ë‚˜ ì£¼ì˜í•´ì•¼í•  ê²ƒì€ Parmeterë¡œ ë“±ë¡ë˜ì§€ ì•Šê³  **Bufferì— ì €ì¥ëœ ê°’**ë“¤ë„ ëª¨ë‘ state_dictì— ì €ì¥ë˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

## ì˜ˆì‹œ: ëª¨ë¸ì˜ ì „ì²´ë¥¼ ì €ì¥

```py
# Modelì€ ìœ„ì—ì„œ êµ¬í˜„í•œ TheModelClassë¥¼ ì‚¬ìš©
model = TheModelClass().cuda()

MODEL_PATH = "saved"
if not os.path.exists(MODEL_PATH):
    os.makedirs(MODEL_PATH)
torch.save(model, os.path.join(MODEL_PATH, "model.pt"))
```

## ì˜ˆì‹œ2: ëª¨ë¸ì˜ Parameterë§Œ ì €ì¥
```py
# Modelì€ ìœ„ì—ì„œ êµ¬í˜„í•œ TheModelClassë¥¼ ì‚¬ìš©
model = TheModelClass().cuda()

MODEL_PATH = "saved"
if not os.path.exists(MODEL_PATH):
    os.makedirs(MODEL_PATH)
torch.save(model.state_dict(), os.path.join(MODEL_PATH, "model.pt"))
```

<br>

# `torch.load()`: model ë¶ˆëŸ¬ì˜¤ê¸°

```py
# ì „ì²´ ëª¨ë¸ì„ ì €ì¥í•œ ê²¨ì›…
model = TheModelClass()
model = torch.load(MODEL_PATH)
model.eval()

# ëª¨ë¸ì˜ state_dictë¥¼ ì €ì¥
model = TheModelClass()
model.load_state_dict(torch.load(MODE_PATH))
model.eval()
```

ìœ„ì—ì„œ `model.eval()`ì´ ê°–ëŠ” ì˜ë¯¸ëŠ” ë¬´ì—‡ì¼ê¹Œ. [ğŸ” What does model.eval() do in pytorch?](https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch/60018731#60018731)

`model.eval()`ì€ `nn.Module`ì—ì„œ train_timeê³¼, eval_timeì—ì„œ ê°ê° ë‹¤ë¥¸ì‘ì—…ì„ ìˆ˜í–‰í•˜ë„ë¡ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜ì´ë‹¤. `model.eval()`ì„ ì„¤ì •í•˜ì§€ ì•Šì•˜ì„ ë•Œ, ì˜ëª»ëœ ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ë ˆì´ì–´ëŠ” **Dropout**, **BatchNorm** ë ˆì´ì–´ê°€ ìˆë‹¤.

`model.eval()`ì„ ì‚¬ìš©í•˜ì—¬ evaluation í•˜ëŠ” ê³¼ì •ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ” ë ˆì´ì–´ë“¤ì„ ì•Œì•„ì„œ ì‚¬ìš©í•˜ì§€ ì•Šë„ë¡ ë§Œë“¤ì–´ì£¼ê²Œ ëœë‹¤. í•˜ì§€ë§Œ ë°˜ë“œì‹œ evaluation ê³¼ì •ì´ ëë‚˜ë©´ `model.train()`ì„ í†µí•´ì„œ trainëª¨ë“œë¡œ ë‹¤ì‹œ ë³€ê²½ì‹œì¼œì•¼ í•œë‹¤.

<br>

# Checkpoints
ì–´ë– í•œ ëª¨ë¸ì—ì„œ ì¶”ë¡ ì´ë‚˜ í•™ìŠµì„ ì¬ê°œí•˜ê±°ë‚˜ Early Stoppingê³¼ ê°™ì€ ê¸°ë²•ì„ ì ìš©í•´ì•¼ í•  ë•Œ, í•™ìŠµì˜ ê²°ê³¼ë¬¼ì„ ê¸°ë¡í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤.

Checkpointsì—ëŠ” ë‹¨ìˆœíˆ <u>ëª¨ë¸ì˜ state_dictë¿ë§Œì•„ë‹ˆë¼ Optimizerì˜ state_dictë„ í¬í•¨í•´ì„œ ì €ì¥</u>í•´ì•¼ í•œë‹¤. í•„ìš”ì— ë”°ë¼ì„œ ì¤‘ë‹¨ ì‹œì ì˜ epoch, lossë“± ì¶”ê°€ ì •ë³´ë¥¼ ì €ì¥í•  ìˆ˜ ìˆë‹¤.

ì—¬ëŸ¬ê°€ì§€ ì •ë³´ë¥¼ ìœ„í•´ì„œ Pythonì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„° íƒ€ì…ì¸ *Dict-type*ìœ¼ë¡œ ë§Œë“  í›„, ìœ„ì—ì„œ ì‚´í´ë³¸ `torch.save()`ë¥¼ ì‚¬ìš©í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•  ë•ŒëŠ” `.tar`í™•ì¥ìë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì¸ ê·œì¹™ì´ë‹¤.

```py
# ì¶”ê°€ ì •ë³´
EPOCH = 5
PATH = "saved/model.pt"
LOSS = 0.4

torch.save({
    'epoch': EPOCH,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': LOSS,
}, PATH)

model = TheModelClass()
optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)

# Checkpointì— ì €ì¥í•œ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']

# model.eval() or model.train() ì‹¤í–‰
```

<br>

# Transfer Learning
ë”¥ëŸ¬ë‹ì„ í•  ë•Œ, ì§ì ‘ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° ëê¹Œì§€ êµ¬í˜„í•˜ì§€ ì•Šê³  ë‹¤ë¥¸ ì‚¬ëŒì´ ì˜ ë§Œë“¤ì–´ ë†“ì€ ëª¨ë¸ì„ ê°€ì ¸ë‹¤ê°€ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë‹¤. ë” ë§ì€ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶€í„° í•™ìŠµì„ í•˜ëŠ” ê²ƒì´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì˜ ë‚˜ì˜¤ê³  ì´ê²ƒì„ ê°€ì§€ê³  ì™€ì„œ ì¼ë¶€ë¥¼ ìˆ˜ì •í•˜ì—¬ ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ì…‹ì˜ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ê²Œ í•˜ëŠ” ê²ƒì´ë‹¤. 

ì´ë ‡ê²Œ ë¶ˆëŸ¬ì˜¨ ëª¨ë¸ì„ ê°€ì§€ê³  í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì„ **Transfer Learning, ì „ì´í•™ìŠµ** ì´ë¼ê³  í•˜ë©° ì˜ ë§Œë“¤ì–´ì§„ ëª¨ë¸ì€ `TorchVision`ì—ì„œ ê³µí•´ì£¼ê³  ìˆë‹¤.

![image](https://user-images.githubusercontent.com/91870042/151110344-7c1e9373-654a-4c97-b636-39e944a84de7.png){: .align-center width="70%"}


## Freezing
ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì„ ê°€ì§€ê³  ì‚¬ìš©í•  ë•Œ, ëª¨ë¸ì˜ ì¼ë¶€ë¶„ì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì„ ë§í•œë‹¤. ëª¨ë“  ë ˆì´ì–´ì— ëŒ€í•´ì„œ í•™ìŠµì‹œí‚¤ì§€ ì•Šê³ , ì¼ë¶€ ë ˆì´ì–´ë§Œ í•™ìŠµì„ ì‹œí‚¤ê³ ì í•  ë•Œ ì‚¬ìš©í•œë‹¤.

```py
from torch import nn
from torchvision import models

class MyNewNet(nn.Module):   
    def __init__(self):
        super(MyNewNet, self).__init__()
        self.vgg19 = models.vgg19(pretrained=True)
        self.linear_layers = nn.Linear(1000, 1)


    # Defining the forward pass    
    def forward(self, x):
        x = self.vgg19(x)        
        return self.linear_layers(x)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

my_model = MyNewNet()
my_model = my_model.to(device)

# ---------------- Freezing ë¶€ë¶„ ------------------
for param in my_model.parameters():
    param.requires_grad = False

for param in my_model.linear_layers.parameters():
param.requires_grad = True
# -------------------------------------------------
```
<br>

# References

[ğŸ“˜ What does model.eval() do in pytorch?](https://stackoverflow.com/questions/60018578/what-does-model-eval-do-in-pytorch/60018731#60018731)

[ğŸ“˜ Pytorchì—ì„œ no_grad()ì™€ eval()ì˜ ì •í™•í•œ ì°¨ì´ëŠ” ë¬´ì—‡ì¼ê¹Œ?](https://coffeedjimmy.github.io/pytorch/2019/11/05/pytorch_nograd_vs_train_eval/)

[ğŸ“˜ SERIALIZATION SEMANTICS](https://pytorch.org/docs/stable/notes/serialization.html#saving-loading-tensors)

[ğŸ“˜ ëª¨ë¸ ì €ì¥í•˜ê¸° & ë¶ˆëŸ¬ì˜¤ê¸°](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)
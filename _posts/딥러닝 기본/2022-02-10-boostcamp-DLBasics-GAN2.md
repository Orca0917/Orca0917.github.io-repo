---
title:  "[Deep Learning Basic] Generative Models Part2"
excerpt: "VAE(Variational Auto Encoder)ì™€ GAN(Generative Adversarial Network) ëŒ€í•œ ì„¤ëª…"

categories:
  - DLBasic
tags:
  - [AI, Naver, BoostCamp, Python, Math]
toc: true
toc_sticky: true

date: 2022-02-10 01:00:00
last_modified_at: 2022-02-10 01:00:00
---
ğŸ“Œ **ì•Œë¦½ë‹ˆë‹¤!**<br>
ì´ë²ˆì— ì‘ì„±ë˜ëŠ” ê¸€ì€ **ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech**ë¥¼ ìˆ˜ê°•í•˜ë©° ì •ë¦¬í•˜ëŠ” ê¸€ì…ë‹ˆë‹¤.<br>
ì—¬ê¸°ì„œ ì¡´ì¬í•˜ëŠ” ê°•ì˜ ìë£Œì˜ ì¶œì²˜ëŠ” ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ì½”ìŠ¤/ìº í”„ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
{: .notice--info}

# Latent Variable Models

- autoencoderëŠ” generative modelì¼ê¹Œ? â†’ ê·¸ë ‡ì§€ ì•Šë‹¤.
- ê·¸ëŸ¬ë©´ ë¬´ì—‡ë•Œë¬¸ì— variational auto-encoderëŠ” generative modelì´ ë  ìˆ˜ ìˆì„ê¹Œ?

<br>

# Variational Auto-encoder

- Variational Inference(VI)ì˜ ëª©ì : **posterior distribution** ì„ ê°€ì¥ ì˜ ê·¼ì‚¬í•˜ëŠ” **variational distribution** ì°¾ê¸°
    - **posterior distribution**: ë‚˜ì˜ observationì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‚´ê°€ ê´€ì‹¬ìˆì–´í•˜ëŠ” í™•ë¥ ë³€ìˆ˜ì˜ í™•ë¥ ë¶„í¬ â†’ ê³„ì‚°í•˜ê¸° ì–´ë µê³ , ë¶ˆê°€ëŠ¥í• ë•Œê°€ ë§ë‹¤. ìˆ˜ì‹ìœ¼ë¡œëŠ” $$p_\theta(z\mid x)$$
    - **Variational distribution**: posterior distributionì„ ê·¼ì‚¬í•˜ëŠ” ë¶„í¬. ìˆ˜ì‹ìœ¼ë¡œëŠ” $$q_\phi(z\mid x)$$
- ì–´ë–¤ê±¸ ê·¼ì‚¬í•˜ëŠ” ê²ƒì„ ì°¾ëŠ”ë‹¤ê³  í•˜ë©´, ì´ ë•Œ í•„ìš”í•œ ê²ƒì€ loss functionì´ë‹¤.
    - Variational InferenceëŠ” loss functionìœ¼ë¡œ KL-divergence(ì¿¨ë°±-ë¼ì´ë¸”ëŸ¬ ë°œì‚°)ì„ ì‚¬ìš©í•œë‹¤.
    - ê²°êµ­, KL-divergenceë¡œ posterior distributionê³¼ variational distributionì˜ ì°¨ì´ë¥¼ ì¤„ì´ê³ ì í•¨

![image](https://user-images.githubusercontent.com/91870042/153741633-fd0f5680-b809-4909-b44a-b2ed9bb4c62b.png){: .align-center width="70%"}

- ìš°ë¦¬ì˜ ëª©ì ì€ variational distributionì„ ì°¾ì•„ë‚´ëŠ”ê²ƒ â†’ Variational Auto-encoderì˜ Encoderë¶€ë¶„
- posterior distributionì„ ëª¨ë¥´ëŠ”ë°, ì–´ë–»ê²Œ variational distributionì„ ì°¾ì•„ë‚¼ ìˆ˜ ìˆì„ê¹Œ?
    - ì˜ˆë¥¼ ë“¤ì–´, loss functionì€ ì£¼ì–´ì ¸ìˆëŠ”ë° targetê°’ì„ ëª¨ë¥´ëŠ” ê²ƒê³¼ ê°™ë‹¤.
- ì´ê²ƒì„ ê°€ëŠ¥í•˜ê²Œ í•´ì£¼ëŠ” ê²ƒì´ ELBO(Evidence Lower Bound) Trickì´ë‹¤.

![image](https://user-images.githubusercontent.com/91870042/153741636-eddf4153-dfd0-4355-b544-5f4ab961d17d.png){: .align-center width="70%"}

- ìš°ë¦¬ì˜ ëª©ì : posterior distributionì™€ varational distributionì˜ KL-Divergenceë¥¼ ì¤„ì´ëŠ” ê²ƒ
- ìœ„ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ, ELBOì˜ ê°’ì„ í¬ê²Œ ì„¤ì •í•´ì„œ Objectiveí•­ì˜ ê°’ì„ ì¤„ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•œë‹¤.
- ì´ì œ, ì´ ELBOê°’ì„ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ ì•Œì•„ë´ì•¼ í•œë‹¤. ELBOëŠ” ë‹¤ìŒì²˜ëŸ¼ ë‚˜ë‰  ìˆ˜ ìˆë‹¤.

![image](https://user-images.githubusercontent.com/91870042/153741647-e4de2bb2-b0bb-4537-8c6a-04bead4915ef.png){: .align-center width="70%"}

- ELBOì˜ ê³„ì‚°ì€ Reconsturtion Termê³¼ Prior Fitting Termìœ¼ë¡œ ë‚˜ë‰œë‹¤.
    - Reconstruction Term: auto-encoderì˜ reconstruction lossë¥¼ ìµœì†Œí™”
        - reconstruction loss ; xë¼ëŠ” ì…ë ¥ì„ latent spaceë¡œ ë³´ëƒˆë‹¤ê°€ ë‹¤ì‹œ decoderë¡œ ëŒì•„ì˜¤ëŠ”ê²ƒ
    - Prior Fitting Term: latent distributionê³¼ prior distributionì„ ê·¼ì‚¬í•˜ê²Œ ë§Œë“ ë‹¤.
- Variational Auto-encoderì˜ ì–´ë ¤ì›€
    - liklihoodë¥¼ ê³„ì‚°í•˜ê¸° ì–´ë ¤ìš´ intractable modelì´ë‹¤.
    - ELBOì˜ 2ë²ˆì§¸ termì¸ Prior Fitting Termì´ ë¯¸ë¶„ì´ ê°€ëŠ¥í•´ì•¼ í•œë‹¤.
        - ë¯¸ë¶„ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ê¸° ìœ„í•´, isotropic Gaussianì„ í™œìš©í•œë‹¤.
    
    ![image](https://user-images.githubusercontent.com/91870042/153741654-2fa1ef14-18f0-4ff5-bb4a-5c52bbc5558c.png){: .align-center width="70%"}
    

<br>

# Adversarial Auto-encoder

![image](https://user-images.githubusercontent.com/91870042/153741656-fc6340d6-12fc-4230-b139-44b24bbf805b.png){: .align-center width="70%"}

- ìœ„ì—ì„œ Variational Auto-Encoderì—ì„œëŠ” ë‹¨ì ìœ¼ë¡œ prior fitting termì´ Gaussian ì„ ë”°ë¼ì•¼ ì—°ì‚°ì´ ê°€ëŠ¥í–ˆë˜ ê²ƒì´ ìˆì—ˆë‹¤. â†’ í•˜ì§€ë§Œ, ë§ì€ ê²½ìš°ì—ì„œ Gaussianì„ í™œìš©í•˜ê³  ì‹¶ì§€ ì•Šì„ ë•Œë„ ìˆë‹¤.
- ì´ê²ƒì„ í•´ê²°í•´ì£¼ëŠ” ê²ƒì´ Adaversarial Auto-encoderì´ë‹¤.
- GANì„ í™œìš©í•´ì„œ latent distribution ì‚¬ì´ì˜ ë¶„í¬ë¥¼ ë§ì¶°ì¤€ë‹¤. 
â†’ Prior Fitting Termì„ GAN Objectiveë¡œ ë°”ê¿”ë²„ë¦°ë‹¤.
- latent distributionì„ sampling í•˜ëŠ” ë¶„í¬ë§Œ ìˆì–´ë„ ê·¼ì‚¬ì‹œí‚¬ ìˆ˜ ìˆë‹¤.
    - uniform distribution

<br>

# Generative Adversarial Network

- Two player game.

![image](https://user-images.githubusercontent.com/91870042/153741662-eaebde1b-1e0c-4ac1-b39d-ed6ff07a9f79.png){: .align-center width="70%"}

- í•œëª…ì´ ìœ„ì¡°ì§€íë¥¼ ë§Œë“¤ê³ , ê·¸ ìœ„ì¡°ì§€íë¥¼ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ íŒë³„í•œë‹¤.
- ë‹¤ì‹œ ì´ íŒë³„í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ë” ì˜ ìœ„ì¡°ì§€íë¥¼ ë§Œë“¤ìˆ˜ ìˆë„ë¡ í•˜ë©° ë°˜ë³µì ìœ¼ë¡œ ì—°ì‚°í•˜ëŠ” êµ¬ì¡°

![image](https://user-images.githubusercontent.com/91870042/153741665-0ec70781-6a91-4b86-b3b2-66ba51731aa8.png){: .align-center width="70%"}

- generatorì™€ discriminator 2ëª…ì˜ í”Œë ˆì´ì–´ê°€ í•˜ëŠ” minmaxê²Œì„
    - minmaxê²Œì„ : í•œëª…ì€ ë†’ì´ë ¤ê³  í•˜ê³ , í•œëª…ì€ ë‚®ì¶”ë ¤ëŠ” ê²Œì„
- Discriminatorì˜ ì…ì¥
    
    ![image](https://user-images.githubusercontent.com/91870042/153741668-9dfc855d-7e5f-4fab-a4c0-8f71e7e6dc32.png){: .align-center width="70%"}
    
    - ìœ„ë¥¼ ìµœì í™” ì‹œí‚¤ëŠ” DëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚œë‹¤.
    
    ![image](https://user-images.githubusercontent.com/91870042/153741670-c782a63d-b199-4460-842f-b9f2ea2b5737.png){: .align-center width="70%"}
    
    - Generatorê°€ ê³ ì •ë˜ì–´ ìˆì„ ë•Œ, ìµœì ìœ¼ë¡œ êµ¬ë¶„ì„ í•´ë‚´ëŠ” optimal distribution.
    - ì´ ê°’ì„ ë‹¤ì‹œ generatorì— ì „ë‹¬ì„ í•´ì£¼ê²Œ ëœë‹¤.
- Generatorì˜ ì…ì¥
    
    ![image](https://user-images.githubusercontent.com/91870042/153741673-36e750fa-2a0f-4bb9-9c5e-81059f095db0.png){: .align-center width="70%"}
    
    - ìœ„ì—ì„œ ì „ë‹¬ë°›ì€ ê°’ì„ ëŒ€ì…í•˜ë©´ ë‚˜ì˜¤ëŠ” ê²°ê³¼
    
    ![image](https://user-images.githubusercontent.com/91870042/153741679-bca64a86-edcb-4a65-8fb2-1267ddcf40b3.png){: .align-center width="70%"}
    
    - GANì˜ Objectiveê°€ ë§ì€ ê²½ìš°, ë°ì´í„°ë¥¼ ì‹¤ì œë¡œ ë§Œë“¤ì–´ëƒˆë‹¤ê³  ìƒê°í•˜ëŠ” distributionê³¼ í•™ìŠµì‹œí‚¨ generatorì‚¬ì´ì˜ Jenson-Shannon Divergenceë¥¼ ìµœì†Œí™” í•˜ëŠ” ê²ƒì´ë¼ê³  ë§í•œë‹¤.
    

## DCGAN

![image](https://user-images.githubusercontent.com/91870042/153741687-3963521e-a2c5-4d69-8d0b-1c4bde33fbf7.png){: .align-center width="70%"}

- ì´ë¯¸ì§€ ë„ë©”ì¸ì—ì„œ GANì„ ì‚¬ìš©í•œ êµ¬ì¡°
- leaked ReLUì˜ ì‚¬ìš©

## Info-GAN

![image](https://user-images.githubusercontent.com/91870042/153741691-3465b607-71e6-4c6b-861e-329959091d46.png){: .align-center width="70%"}

- ì´ë¯¸ì§€ë§Œ ë§Œë“œëŠ” ê²ƒì´ ì•„ë‹ˆë¼, classë„ ê°™ì´ ë§Œë“¤ì–´ë‚¸ë‹¤.
- GANì´ íŠ¹ì • ëª¨ë“œì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤. â†’ multi modal distribution

## Text2Image

![image](https://user-images.githubusercontent.com/91870042/153741695-31c72b36-138e-4896-8ffa-88da1b9fe4e0.png){: .align-center width="70%"}

## Puzzle-GAN

![image](https://user-images.githubusercontent.com/91870042/153741700-5ede984d-fcc8-42ae-a550-f7feb06ddfbf.png){: .align-center width="70%"}

- ì´ë¯¸ì§€ì˜ ë¶€ë¶„ë§Œì„ ê°€ì§€ê³  ë³µì›í•˜ëŠ” ê²ƒ

## Cycle GAN

![image](https://user-images.githubusercontent.com/91870042/153741703-779f3955-0325-4891-8a87-95b7982096a4.png){: .align-center width="70%"}

- ì´ë¯¸ì§€ ì‚¬ì´ì˜ ë„ë©”ì¸ì„ ë°”ê¿”ì£¼ëŠ” ê²ƒ
- Cycle-consistency lossë¥¼ ì‚¬ìš©

![image](https://user-images.githubusercontent.com/91870042/153741707-fe869c70-6451-4e10-94a2-951e32ad9cd6.png){: .align-center width="70%"}

## Star-GAN

![image](https://user-images.githubusercontent.com/91870042/153741709-851757ff-06f3-4957-a085-9c5cf96d9291.png){: .align-center width="70%"}

## Progressive-GAN

- ì €í•´ìƒë„ì—ì„œ ê³ í•´ìƒë„ë¡œ ì ì°¨ ëŠ˜ë ¤ê°€ë©´ì„œ í•™ìŠµì„ ì§„í–‰

![image](https://user-images.githubusercontent.com/91870042/153741715-72eb993a-8e06-4157-81c9-2140521b63b3.png){: .align-center width="70%"}
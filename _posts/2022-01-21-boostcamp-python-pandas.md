---
title:  "[Python Basics for AI] Python Pandas"
excerpt: "Pandas: íŒŒì´ì¬ ë°ì´í„° ì²˜ë¦¬ì˜ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬"

categories:
  - python
tags:
  - [AI, Naver, BoostCamp, Python, Pandas]
toc: true
toc_sticky: true
 
date: 2022-01-21 01:00:00
last_modified_at: 2022-01-21 01:00:00
---
ğŸ“Œ **ì•Œë¦½ë‹ˆë‹¤!**<br>
ì´ë²ˆì— ì‘ì„±ë˜ëŠ” ê¸€ì€ **ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ìº í”„ AI Tech**ë¥¼ ìˆ˜ê°•í•˜ë©° ì •ë¦¬í•˜ëŠ” ê¸€ì…ë‹ˆë‹¤.<br>
ì—¬ê¸°ì„œ ì¡´ì¬í•˜ëŠ” ê°•ì˜ ìë£Œì˜ ì¶œì²˜ëŠ” ë„¤ì´ë²„ ë¶€ìŠ¤íŠ¸ì½”ìŠ¤/ìº í”„ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
{: .notice--info}

![image](https://user-images.githubusercontent.com/91870042/144968064-c52e30d3-dd43-4fe4-9b23-f393ca5aca1c.png){: .align-center}

# Pandas
êµ¬ì¡°í™”ëœ ë°ì´í„°ì˜ ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ëŠ” Pythonë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œì„œ, `Panel data`ì˜ ì¤„ì„ë§ë¡œ `Pandas`ê°€ ë˜ì—ˆë‹¤. ê³ ì„±ëŠ¥ arrayê³„ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ numpyì™€ í†µí•©í•˜ì—¬, ê°•ë ¥í•œ `ìŠ¤í”„ë ˆë“œì‹œíŠ¸`ì²˜ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. Pandasì—ì„œëŠ” ì¸ë±ì‹±ê³¼ ì—°ì‚°ìš©í•¨ìˆ˜, ì „ì²˜ë¦¬ í•¨ìˆ˜ë“±ì„ numpyì™€ ë¹„ìŠ·í•˜ê²Œ ì œê³µí•˜ê³  ìˆìœ¼ë©° ì£¼ë¡œ, **ë°ì´í„° ì²˜ë¦¬ ë° í†µê³„ ë¶„ì„**ì„ ìœ„í•´ì„œ ì‚¬ìš©ëœë‹¤.

## Tabularí˜•íƒœì˜ ë°ì´í„° ëª…ì¹­
![image](https://user-images.githubusercontent.com/91870042/144960142-1d7b4830-c691-43d4-8213-8b0ce99302ee.png){: .align-center}

- `Data table`: ë°ì´í„°ê°€ ë“¤ì–´ìˆëŠ” í…Œì´ë¸”. ì—‘ì…€ì˜ Sheetì™€ ë¹„ìŠ·í•˜ë‹¤.
- `Attribute`, `column`: ë°ì´í„°ì˜ ì†ì„±ì„ ì˜ë¯¸í•œë‹¤.
- `instance`, `tuple`, `row`: í•œ ë°ì´í„°ì˜ ê°€ë¡œ ì—´ì„ ì˜ë¯¸í•œë‹¤.
- `data`, `ê°’`, `value`: í–‰ê³¼ ì—´ì´ ë§Œë‚˜ëŠ” í•˜ë‚˜ì˜ ì…€ì„ ì˜ë¯¸í•œë‹¤.

## Pandas ì„¤ì¹˜
```
conda create -n ml python
activate ml
conda install pandas

jupyter notebook # ì£¼í”¼í„° ì‹¤í–‰í•˜ê¸°
```

## ë°ì´í„° ë¡œë”©
```py
import pandas as pd

data_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data"
 # CSVíƒ€ì…ì˜ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , separaterëŠ” ë¹ˆê³µê°„ìœ¼ë¡œ ì§€ì •í•˜ë©° Columnì€ ì§€ì •í•˜ì§€ ì•ŠëŠ”ë‹¤.)
df_data = pd.read_csv(data_url, sep="\s+", header=None) # sep: ë„ì–´ì“°ê¸°ê°€ í•˜ë‚˜ ì´ìƒ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤.
# Column ëª… ì§ì ‘ ì§€ì •í•˜ê¸°
df_data.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']
df_data.head() #ì²˜ìŒ 5ì¤„ ì¶œë ¥
```
<br>

# Series
- `Series`: ë°ì´í„°í”„ë ˆì„ ì¤‘ í•˜ë‚˜ì˜ columnì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ì˜ ëª¨ìŒ Object
- `DataFrame`: DataTable ì „ì²´ë¥¼ í¬í•¨í•˜ëŠ” Object

![image](https://user-images.githubusercontent.com/91870042/144961072-9678de0f-3bcc-4257-931f-d1bd6256e09b.png){: .align-center}

## ì‚¬ìš©ë²•
```py
Series(data=None, index=None, dype=None, name=None, copy=False, fastpath=False)
```
```py
list_data = [1, 2, 3, 4, 5]
example_obj = Series(data = list_data)
print(example_obj)
```
```
0   1
1   2
2   3
3   4
4   5
dtype: int64
```
SeriesëŠ” `index`ì™€ `values`ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë˜í•œ indexì˜ ì´ë¦„ì„ ì§ì ‘ ì§€ì •í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤.

```py
list_data = [1, 2, 3, 4, 5]
list_name = ["a", "b", "c", "d", "e"]
example_obj = Series(data = list_data, index=list_name)
print(example_obj)
```

ê¸°ë³¸ì ìœ¼ë¡œ Seriesì™€ Dataframeì€ **indexë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ê°€ ìƒì„±**ì´ ë˜ê¸° ë•Œë¬¸ì—, dataì˜ í¬ê¸°ë³´ë‹¤ indexì˜ í¬ê¸°ê°€ ë” í° ê²½ìš°ì— ë‚˜ë¨¸ì§€ ê°’ë“¤ì€ `NaN`ê°’ìœ¼ë¡œ ì§€ì •ì´ ëœë‹¤.
```py
list_data = [1, 2, 3, 4, 5]
list_name = ["a", "b", "c", "d", "e", "f", "g"]
example_obj = Series(data = list_data, index=list_name)
print(example_obj)
```
```
a   1.0
b   2.0
c   3.0
d   4.0
e   5.0
f   NaN
g   NaN
dtype: float64
```
<br>

Dict typeìœ¼ë¡œ Seriesìƒì„±
```py
dict_data = {"a":1, "b":2, "c":3, "d":4, "e":5}
example_obj = Series(dict_data, dtype=np.float32, name="example_data")
print(example_obj)
```
```
a   1.0
b   2.0
c   3.0
d   4.0
e   5.0
Name: example_data, dtype: float32
```
<br>

Data indexë¡œ ê°’ì— ì ‘ê·¼í•˜ëŠ” ë°©ë²•
```py
example_obj["a"]
example_obj["a"] = 3.2
```

## ë‹¤ì–‘í•œ í•¨ìˆ˜
- `astype`: ë°ì´í„° íƒ€ì…ì„ ë³€ê²½í•œë‹¤
- `values`: Seriesì˜ Valueê°’ë§Œ ì¶œë ¥í•´ì„œ ë³´ì—¬ì¤€ë‹¤
- `index`: Seriesì˜ Indexê°’ë§Œ ì¶œë ¥í•´ì„œ ë³´ì—¬ì¤€ë‹¤.
- `name`: Dataì— ëŒ€í•œ ì´ë¦„ì„ ì§ì ‘ ì§€ì •í•  ìˆ˜ ìˆë‹¤.

<br>

# DataFrame
ë°ì´í„° í”„ë ˆì„ì—ì„œ ê°’ì„ ì•Œê¸° ìœ„í•´ì„œëŠ” ë°ì´í„° í”„ë ˆì„ì˜ `index`ê°’ê³¼ `column`ê°’ì„ ì•Œì•„ì•¼ í•œë‹¤. ë˜í•œ ë°ì´í„° í”„ë ˆì„ì€ ê°ê°ì˜ ë°ì´í„° íƒ€ì…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤. Seriesë¥¼ ëª¨ì•„ì„œ ë§Œë“  Data Tableì´ê¸° ë•Œë¬¸ì— ê¸°ë³¸ì ìœ¼ë¡œ 2ì°¨ì›ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤.

![image](https://user-images.githubusercontent.com/91870042/144962636-8e13c1f1-e4fb-4ae0-b4e7-fb98b95f2a7d.png){: .align-center}

## columnì„ ì„ íƒí•˜ëŠ” ë°©ë²•
- `.`ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
```py
df.first_name
```

- `index`ë¡œ ì ‘ê·¼í•˜ëŠ” ë°©ë²•
```py
df["first_name"]
```

## indexing
- `loc`: index location, ì¸ë±ìŠ¤ì˜ **ì´ë¦„**
- `iloc`: index position, ì¸ë±ìŠ¤ì˜ **ë²ˆí˜¸**

```py
s = pd.Series(np.nan, index=[49, 48, 47, 46, 45, 1, 2, 3, 4, 5])
s.loc[:3] # indexê°’ì´ 3ì´ ë‚˜ì˜¬ ë•Œ ê¹Œì§€ ì¶œë ¥
s.iloc[:3] # 3ë²ˆì§¸ indexê¹Œì§€ ì¶œë ¥
```
```
49  NaN
48  NaN
47  NaN
46  NaN
45  NaN
1   NaN
2   NaN
3   NaN
dtype: float64

49  NaN
48  NaN
47  NaN
dtype: float64
```

## handling
ìƒˆë¡œìš´ Columnì— ê°’ì„ Boolean ë¹„êµë¡œ í• ë‹¹í•˜ëŠ” ë°©ë²•
```py
df.debt = df.age > 40
```

Columnì‚­ì œ
```py
del df["debt"]  # ë©”ëª¨ë¦¬ ìƒì—ì„œ ì‚­ì œ - dfì— ë³€í™”ê°€ ìƒê¹€
df.drop("debt", axis=1) # ë©”ëª¨ë¦¬ ìƒì—ì„œ ì‚­ì œX - dfì— ë³€í™”ê°€ ì—†ìŒ
```

- `T`: Transpose(ì „ì¹˜)
- `values`: ê°’ ì¶œë ¥
- `to_csv()`: csví˜•ì‹ìœ¼ë¡œ ë°ì´í„°í”„ë ˆì„ì„ ë³€í™˜í•œë‹¤.

<br>

# selection & drop

## Selection with column names
- í•œê°œì˜ columnì„ ì„ íƒí•˜ëŠ” ê²½ìš°
```py
df["account"].head()
```

- 2ê°œ ì´ìƒì˜ columnì„ ì„ íƒí•˜ëŠ” ê²½ìš°
```py
df[["account", "street", "state"]].head()
```

## Selcetion with index number
```py
df[:3] # Columnì´ë¦„ ì—†ì´ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, rowë¥¼ ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œí•´ì¤€ë‹¤.
```

||account|name|street|city|state|postal-code|Jan|Feb|Mar|
|---|---|---|---|---|---|---|---|---|---|
|0|211829|Kerluke, Koepp and Kilpert|34456 Sean Highway|New Jaycob|Texas|28752|1000|62000|35000|
|1|320563|Walter-Trantow|1311 Alvis Tunnel|Port Khadijah|Nort Carolina|38365|95000|45000|35000|
|2|648336|Bashirian, Kunde and Price|62184 Schanberger Underpass Apt. 231|New Lilianland|lowa|76517|91000|120000|35000|

```py
account_series = df["account"]
account_series["account"][:3] # ì¹¼ëŸ¼ëª…ê³¼ í•¨ê»˜ row indexë¥¼ ì‚¬ìš©í•˜ë©´, í•´ë‹¹ ì¹¼ëŸ¼ë§Œ ë³´ì—¬ì¤€ë‹¤.
account_series[[0, 1, 2]]
account_series[account_series < 5000] # Boolean index
```
```
0   211829
1   320563
2   648336
Name: account, dtype: int64

0   211829
1   320563
2   648336
Name: account, dtype: int64

0   211829
3   109996 
4   121213
5   132971
...
11  231907
12  242368
Name: account, dtype: int64
```

## index ë³€ê²½
```py
df.index = df["account"]
del df["account"]
df.head()
```

||name|street|city|state|postal-code|Jan|Feb|Mar|
|---|---|---|---|---|---|---|---|---|
|account|||||||||
|211829|Kerluke, Koepp and Kilpert|34456 Sean Highway|New Jaycob|Texas|28752|1000|62000|35000|
|320563|Walter-Trantow|1311 Alvis Tunnel|Port Khadijah|Nort Carolina|38365|95000|45000|35000|
|648336|Bashirian, Kunde and Price|62184 Schanberger Underpass Apt. 231|New Lilianland|lowa|76517|91000|120000|35000|


## basic, loc, iloc selection
![image](https://user-images.githubusercontent.com/91870042/144964814-384eca57-6b67-41a0-9634-850a357c1535.png){: .align-center}

![image](https://user-images.githubusercontent.com/91870042/144964837-c2a1942a-b10d-4e01-9e3c-7c5fa74f2170.png){: .align-center}

## index ì¬ì„¤ì •
```py
df.index = list(range(0, 15)) #ë°©ë²•1
df.reset_index(drop=True) #ë°©ë²•2
df.reset_index(inplace=True, drop=True)
```

## data drop
indexì˜ ë²ˆí˜¸ë¡œ í•˜ë‚˜ì˜ rowë¥¼ ì§€ìš¸ ìˆ˜ ìˆë‹¤. ì‹¤ì œ ë°ì´í„° í”„ë ˆì„ì— ì ìš©ì´ ë˜ì§€ëŠ” ì•Šê³ , ë°ì´í„°í”„ë ˆì„ì— ì ìš©ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” `inplace=True`ì˜µì…˜ì„ ì§€ì •í•´ì•¼í•œë‹¤.
```py
df.drop(1)
df.drop(1, inplace=True)
```
ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ì—¬ dropí•  ìˆ˜ ìˆë‹¤. `axis=1`ë¡œ ì„¤ì •í•˜ê²Œ ë˜ë©´, ì„¸ë¡œì¤„ì´ ì‚­ì œê°€ ëœë‹¤.
```py
df.drop("city", axis=1, inplace=True)
```

<br>

# dataframe operations

## Series operation

|s1ìƒì„±|s2ìƒì„±|
|:---:|:---:|
|![image](https://user-images.githubusercontent.com/91870042/144965484-4f78fd15-ec22-41f9-8331-5028bea5bca8.png){: .align-center}|![image](https://user-images.githubusercontent.com/91870042/144965513-d1f39210-cae0-4aa0-a936-3f893324fbea.png){: .align-center}|

![image](https://user-images.githubusercontent.com/91870042/144965543-8a42eab5-2ff1-4584-8dbd-e872820beddf.png){: .align-center}

## dataframe operation

|df1ìƒì„±|df2ìƒì„±|
|:---:|:---:|
|![image](https://user-images.githubusercontent.com/91870042/144965704-b8b4b95b-facc-4807-8c79-86220dd1eb74.png){: .align-center}|![image](https://user-images.githubusercontent.com/91870042/144965714-55258a40-1948-436c-b0e5-1d2ff4417d8d.png){: .align-center}|

![image](https://user-images.githubusercontent.com/91870042/144965740-995e14d6-8f93-4c09-af66-bc3915b9fb48.png){: .align-center}

## series + dataframe
```py
df = DataFrame(np.arange(16).reshape(4, 4), columns=list("abcd"))
s2 = Series(np.arange(10, 14))
print(df + s2)
print(df.add(s2, axis=0))
```

||a|b|c|d|0|1|2|3|
|---|---|---|---|---|---|---|---|---|
|0|NaN|NaN|NaN|NaN|NaN|NaN|NaN|NaN|
|1|NaN|NaN|NaN|NaN|NaN|NaN|NaN|NaN|
|2|NaN|NaN|NaN|NaN|NaN|NaN|NaN|NaN|
|3|NaN|NaN|NaN|NaN|NaN|NaN|NaN|NaN|

||a|b|c|d|
|---|---|---|---|---|
|0|10|11|12|13|
|1|15|16|17|18|
|2|20|21|22|23|
|3|25|26|27|28|

<br>

# lambda, map, apply
## map
pandasì˜ seriesíƒ€ì…ì˜ ë°ì´í„°ì—ë„ mapí•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. mapì„ í™œìš©í•˜ì—¬ `dict`, `sequence`í˜• ìë£Œë“¤ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°”ë¡œ ë³€í˜•í•  ìˆ˜ ìˆë‹¤.

### Dictë¥¼ ì´ìš©í•œ mapping
```py
z = {1: 'A', 2: 'B', 3: 'C'}
s1.map(z).head(5)
```
```
0   NaN
1   A
2   B
3   C
4   NaN
dtype: object
```
```py
df["sex_code"] = df.sex.map({"male":0, "female":1})
```

### replace function
```py
df.sex.replace({"male":0, "female":1})
df.sex.replace(["male", "female"], [0, 1], inplace=True)
```

## Lambda
```py
s1 = Series(np.arnage(10))
s1.map(lambda x: x**2).head()
```

## Apply
mapê³¼ ë‹¬ë¦¬, Seriesì „ì²´ì— í•´ë‹¹ í•¨ìˆ˜ë¥¼ ì ìš©í•  ìˆ˜ ìˆë‹¤. ì…ë ¥ê°’ì„ Seriesë°ì´í„°ë¡œ ì…ë ¥ë°›ì•„ì„œ ì¡°ì‘í•  ìˆ˜ ìˆë‹¤.
```py
df_info = df[["earn", "height", "age"]]

f = lambda x : x.max() - x.min()
df_info.apply(f)

df_info.sum()
df_info.apply(sum)
```

||earn|height|age|
|---|---|---|---|
|0|79571.299011|73.89|49|
|1|96396.988643|66.23|62|
|2|48710.666947|63.77|33|
|3|80478.096153|63.22|95|
|4|82089.345498|63.08|43|

```
earn    318047.708444
height  19.870000
age     73.000000
dtype: float64

earn    4.474344e+07
height  9.183125e+04
age     6.250800e+04
dtype: float64
```

### applymap
Seriesë‹¨ìœ„ê°€ ì•„ë‹ˆë¼ elementë‹¨ìœ„ë¡œ í•¨ìˆ˜ë¥¼ ì ìš©í•  ë•Œ `applymap`ì„ ì‚¬ìš©í•œë‹¤. ì´ê²ƒì€ Seriesë‹¨ìœ„ì— `Apply`ë¥¼ ì ìš©í•œê²ƒê³¼ ë™ì¼í•œ ê²°ê³¼ë¥¼ ë³´ì¸ë‹¤.
```py
f = lambda x : -x
df_info.applymap(f).head() # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ê°’ì— -ê°€ ë¶™ì–´ì„œ ì¶œë ¥
```

<br>

# Pandas built-in Functions
## Describe
`describe`ëŠ” numeric typeì˜ ë°ì´í„° ìš”ì•½ ì •ë³´ë¥¼ ë³´ì—¬ì¤€ë‹¤. ê·¸ ì´ì™¸ì˜ objectë°ì´í„° íƒ€ì…ì€ ë³´ì—¬ì£¼ì§€ ì•ŠëŠ”ë‹¤.

## Unique
`unique`ëŠ” series ë°ì´í„°ì˜ ìœ ì¼í•œ ê°’ì„ ë°˜í™˜í•œë‹¤.

## Sum
`sum`ì€ ê¸°ë³¸ì ì¸ column ë˜ëŠ” rowê°’ì˜ ì—°ì‚°ì„ ì§€ì›í•œë‹¤. ë˜í•œ, ì¶•ì„ ì§€ì •í•´ì„œ í•©ì„ ê³„ì‚°í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤.
- `axis = 0` : ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•¨í•˜ì—¬ ê²°ê³¼ì ìœ¼ë¡œ í–‰ë°©í–¥ìœ¼ë¡œ ê²°ê³¼ê°€ ë‚¨ëŠ”ë‹¤.
- `axis = 1` : í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•˜ì—¬ ê²°ê³¼ì ìœ¼ë¡œ ì—´ë°©í–¥ìœ¼ë¡œ ê²°ê³¼ê°€ ë‚¨ëŠ”ë‹¤.

## isnull
ì–´ë– í•œ íŠ¹ì •í•œ ê°’ì´ NaN(null)ê°’ì˜ indexë¥¼ ë°˜í™˜í•œë‹¤. ì‘ìš©í•˜ì—¬, ì „ì²´ ë°ì´í„°í”„ë ˆì„ì˜ ë¹ˆ ê°’ì„ ì°¾ê³  ì‹¶ë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì°¾ì„ ìˆ˜ ìˆë‹¤.
```py
df.isnull().sum()
```

## sort_values
ë°ì´í„° í”„ë ˆì„ì˜ ê°’ì—ì„œ `column`ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•´ì„œ ë³´ì—¬ì¤„ ìˆ˜ ìˆë‹¤. 
```py
df.sort_values(["age", "earn"], ascending = True).head()
```

## value_counts
ë°ì´í„° í”„ë ˆì„ì—ì„œ í•´ë‹¹ ê°’ì´ ëª‡ë²ˆ ë“±ì¥í•˜ëŠ”ì§€ êµ¬í•  ìˆ˜ ìˆë‹¤.
```py
df["sex"].value_counts(sort = True)
df["sex"].value_counts(sort = True) / len(df) # ë“±ì¥ ë¹„ìœ¨ì„ êµ¬í•œë‹¤.
```

## Correlation & Covariance
ìƒê´€ê³„ìˆ˜(`corr`)ì™€ ê³µë¶„ì‚°(`cov`)ì˜ ê°’ì„ êµ¬í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì´ë‹¤.
```py
df.corr() # ì „ì²´ ê° í•­ëª©ê°„ì˜ ìƒê´€ê´€ê³„
df["age"].corr(df["earn"]) # ë‚˜ì´ì™€ ì†Œë“ê°„ì˜ ìƒê´€ê´€ê³„
df.age.cov(df.earn) # ë‚˜ì´ì™€ ì†Œë“ê°„ì˜ ê³µë¶„ì‚°
df.corrwith(df.earn) # ì „ì²´í•­ëª©ê³¼ ì†Œë“ê°„ì˜ ìƒê´€ê´€ê³„
```
<br>

# Groupby
SQLì—ì„œì˜ groupbyëª…ë ¹ì–´ì™€ ë™ì¼í•˜ë‹¤. groupbyëª…ë ¹ì–´ê°€ ì‹¤í–‰ë˜ì—ˆì„ ë•ŒëŠ” **(split â†’ apply â†’ combine)**ì˜ ê³¼ì •ì„ ê±°ì³ì„œ ì—°ì‚°ì„ ì§„í–‰í•œë‹¤.

![image](https://user-images.githubusercontent.com/91870042/144971886-6ba26863-e5fa-4c24-8635-7d133d5d5091.png){: .align-center}

```py
df.groupby("ë¬¶ìŒì˜ ê¸°ì¤€ì´ ë˜ëŠ” ì¹¼ëŸ¼").['ì ìš©ë°›ëŠ” ì¹¼ëŸ¼'].ì ìš©ë°›ëŠ” ì—°ì‚°
df.groupby("Team").["points"].sum()

# í•œ ê°œ ì´ìƒì˜ ì¹¼ëŸ¼ì„ ë¬¶ì–´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ ê°€ëŠ¥í•˜ë‹¤
df.groupby(["Team", "Year"]).["points"].sum()
```
```
Team
Devils  1536
Kings   2285
Riders  3049
Royals  1505
kings   812
Name: Points, dtype: int64

Team    Year
Devils  2014    863
        2015    673
Kings   2014    741
        2016    756
        2017    788
Riders  2014    876
        2015    789
        2016    694
```

## Hierarchical Index
`groupby`ëª…ë ¹ìœ¼ë¡œ ë‚˜ì˜¨ ê²°ê³¼ë¬¼ë„ ë°ì´í„° í”„ë ˆì„ì´ë‹¤. ìœ„ì—ì„œ ë³¸ ì˜ˆì‹œì™€ ê°™ì´ 2ê°œ ì´ìƒì˜ ì¹¼ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ groupbyë¥¼ í•˜ê²Œ ë˜ë©´ ì¸ë±ìŠ¤ê°€ 2ê°œ ì´ìƒ ìƒì„±ì´ ëœë‹¤. í•´ë‹¹ ë°ì´í„°í”„ë ˆì„ì„ `unstack()`, `swaplevel()`ì˜ ì—°ì‚°ì„ í†µí•´ì„œ í˜•ì‹ì„ ë°”ê¿€ ìˆ˜ ìˆë‹¤.

### unstack
`unstack()`ì€ groupìœ¼ë¡œ ë¬¶ì¸ ë°ì´í„°ë¥¼ matrixí˜•íƒœë¡œ ì „í™˜í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. ìœ„ì—ì„œ `Team`ê³¼ `Year`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ groupbyë¥¼ ìˆ˜í–‰í•œ ê²°ê³¼ì—ì„œ unstackì„ í•˜ê²Œ ë˜ë©´, 2ê°œì˜ indexê°€ í–‰ê³¼ ì—´ì´ë˜ì–´ì„œ ê°’ì´ ë³´ì—¬ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
> unstack()ì´ ëœ ìƒíƒœì—ì„œ stack()ì„ ë‹¤ì‹œ í•´ì£¼ë©´, ê¸°ì¡´ì˜ ë°ì´í„°í”„ë ˆì„ì˜ ìƒíƒœë¡œ ë˜ëŒì•„ê°„ë‹¤.

```py
h_index = df.groupby(["Team", "Year"]).["points"].sum()
h_index.unstack()
```

![image](https://user-images.githubusercontent.com/91870042/144972890-79d3d010-5176-43b2-bbda-044a2d238c26.png){: .align-center}

### swaplevel
`swaplevel()`ì€ ì¸ë±ìŠ¤ì˜ ë ˆë²¨ì„ ì„œë¡œ ë°”ê¾¸ì–´ ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. ìœ„ì˜ ì˜ˆì‹œì—ì„œ 0ë²ˆì§¸, 1ë²ˆì§¸ ë ˆë²¨ì€ ê°ê°, "Team", "Year"ì´ë‹¤. ì´ë²ˆì—ëŠ” ë°˜ëŒ€ë¡œ, **Yearë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¨¼ì € groupìœ¼ë¡œ ë¬¶ê³ , ê·¸ ì•ˆì—ì„œ ë‹¤ì‹œ Teamìœ¼ë¡œ ë¬¶ì€ ê²°ê³¼**ë¥¼ ì¶œë ¥í•´ ì£¼ê¸° ìœ„í•´ì„œëŠ” swaplevel()ì„ ì‚¬ìš©í•˜ë©´ ëœë‹¤.
```py
h_index.swaplevel()
h_index.swaplevel().sortlevel(0)
```

![image](https://user-images.githubusercontent.com/91870042/144973115-ff0440b1-159d-476e-9210-9a4d57eca4e6.png){: .align-center}


### operations
ìœ„ì—ì„œ ì–»ì€ ê²°ê³¼ì—ì„œ ë‹¤ì‹œ, ë‹¤ì–‘í•œ ì—°ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ”ë° ê·¸ì¤‘ì— í•© ì—°ì‚°ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.
- `sum`
```py
h_index.sum(level=0) # Teamì„ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ë¥¼ í•©ì‚°
h_index.sum(level=1) # ì—°ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ë¥¼ í•©ì‚°
```

## grouped
ë°ì´í„°í”„ë ˆì„ì—ì„œ ê·¸ë£¹ì„ ì§€ì •í•´ **split**ëœ ìƒíƒœë¥¼ ì¶”ì¶œí•´ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ ë•Œì˜ ê²°ê³¼ëŠ” `tuple`í˜•íƒœë¡œ ì§€ì •ë˜ì–´ ìˆì–´ì„œ ê·¸ë£¹ì˜ keyê°’ê³¼ valueê°’ì„ ë½‘ì•„ë‚¼ ìˆ˜ ìˆë‹¤.
```py
grouped = df.groupby("Team")
for name, group in grouped:
    print(name)
    print(group)
```
![image](https://user-images.githubusercontent.com/91870042/144973994-9422c5de-cd03-4a1d-9ce8-edde9e0fd70e.png){: .align-center}

ìœ„ì˜ ê²°ê³¼ì—ì„œ íŠ¹ì • ê·¸ë£¹ì˜ ê²°ê³¼ë§Œ ë³´ê³  ì‹¶ë‹¤ë©´, `get_group`ì„ ì‚¬ìš©í•´ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```py
grouped.get_group("Devils")
```

ì´ë ‡ê²Œ groupbyë¡œ ì¶”ì¶œëœ ìë£Œë¥¼ ì´ìš©í•´ 3ê°€ì§€ ìœ í˜•ì˜ `apply`ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.

### Aggregation
`aggregation`ì€ ìš”ì•½ëœ í†µê³„ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ëŠ” í•¨ìˆ˜ì´ë‹¤.
```py
import numpy as np

grouped.agg(sum)
grouped.agg(np.mean)

# íŠ¹ì • ì¹¼ëŸ¼ì— ì—¬ëŸ¬ê°œì˜ í•¨ìˆ˜ë¥¼ applyí•  ìˆ˜ ìˆë‹¤.
grouped['points'].agg([np.sum, np.mean, np.std])
```
![image](https://user-images.githubusercontent.com/91870042/144974475-d5ad74cf-6d03-494e-bd90-f4c35e7da617.png){: .align-center}

### Transformation
`transformation`ì€ ì¶”ì¶œëœ ìë£Œì˜ ì •ë³´ë¥¼ lambdaì™€ ê°™ì€ í•¨ìˆ˜ë¥¼ í†µí•´ ë³€í™˜í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. aggregationê³¼ ë‹¬ë¦¬ keyê°’ ë³„ë¡œ ìš”ì•½ëœ ì •ë³´ê°€ ì•„ë‹ˆë‹¤. ë”°ë¼ì„œ íŠ¹ì • ê·¸ë£¹ì„ ì„ íƒí•´ì„œ ì ìš©ì‹œí‚¤ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë‹¤. 

```py
score = lambda x: (x)
grouped.transform(score)

score = lambda x: (x.max())
grouped.transform(score)

score = lambda x: (x - x.mean()) / x.std()
grouped.transform(score)
```
![image](https://user-images.githubusercontent.com/91870042/144976064-3c725651-f2fa-4522-b904-d1b0b3e85cc8.png){: .align-center}


### Filtration
`filtration`ì€ ì–»ì–´ë‚¸ ìë£Œì—ì„œ íŠ¹ì • ì •ë³´ë¥¼ ì œê±°í•˜ì—¬ ë³´ì—¬ì£¼ëŠ” **í•„í„°ë§**ì˜ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. `filter`ì•ˆì—ëŠ” booleanì¡°ê±´ì´ ì¡´ì¬í•´ì•¼í•˜ë©°, `len(x)`ëŠ” ê·¸ë£¹ìœ¼ë¡œ ë¬¶ì¸ ë°ì´í„°í”„ë ˆì„ì˜ ê°œìˆ˜ë¥¼ ì˜ë¯¸í•œë‹¤.

```py
df.groupby('Team').filter(lambda x: len(x) >= 3)
df.groupby('Team').filter(lambda x: x["Rank"].sum() > 2)
df.groupby('Team').filter(lambda x: x["Points"].sum() > 1000)
df.groupby('Team').filter(lambda x: x["Rank"].sum() > 1)
```

<br>

# Case Study
ì‹¤ì œ ë°ì´í„°ë¥¼ ì´ìš©í•´ì„œ ë°ì´í„°ë¥¼ ë¶„ì„
[ğŸ“„phone_data.csv](https://www.shanelynn.ie/wp-content/uploads/2015/06/phone_data.csv)

```py
import dateutil

df_phone = pd.read_csv("phone_data.csv")
df_phone['date'] = df_phone['date'].apply(dateutil.parser.parse, dayfirst = True)
df_phone.read()
```
![image](https://user-images.githubusercontent.com/91870042/144977727-0425fd03-cb57-47e2-9fdb-d47ef2cf69d1.png){: .align-center}

> ì›”ë³„ë¡œ ì‚¬ìš©ëŸ‰ ë¶„ì„í•˜ê¸°

```py
df_phone.groupby('month')['duration'].sum()
```
```
month
2014-11     26639.441
2014-12     14641.870
2015-01     18233.299
2015-02     15522.299
2015-03     22750.441
Name: duration, dtype: float64
```

> ì›”ë³„ë¡œ í†µí™”ëŸ‰ ë¶„ì„í•˜ê¸°

```py
df_phone[df_phone['item'] == 'call'].groupby('network')['duration'].sum()
```

> ì›”ë³„ë¡œ í†µí™”, ë°ì´í„°, ë¬¸ì ì‚¬ìš©í•œ ì¼ ìˆ˜ ë¶„ì„í•˜ê¸°

```py
df_phone.groupby(['month', 'item'])['date'].count()
df_phone.groupby(['month', 'item'])['date'].count().unstack()
```

<br>

# Pivot table & Crosstab
## Pivot Table
ì—‘ì…€ì—ì„œ ë§ì´ ì‚¬ìš©í•˜ë˜ `í”¼ë´‡`ê¸°ëŠ¥ê³¼ ë™ì¼í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•œë‹¤. Indexì¶•ì€ groupbyì™€ ë™ì¼í•˜ì§€ë§Œ, ì¹¼ëŸ¼ê°’ì— ì¶”ê°€ë¡œ ë¼ë²¨ë§í•˜ì—¬ ê° ë°ì´í„°ë³„ë¡œ aggfuncì˜ ê²°ê³¼ ê°’ì„ ë³´ì—¬ì¤€ë‹¤.

```py
df_phone.pivot_table(["duration"], 
                index=[df.phone.month, df_phone.item], 
                columns=df.phone.network, 
                aggfunc="sum", 
                fill_value=0)
```

## Corsstab
2ê°œì˜ ì¹¼ëŸ¼ê°„ì˜ êµì°¨ ë¹ˆë„, ë¹„ìœ¨, ë§ì…ˆì„ êµ¬í• ë•Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ `crosstab`ì´ë‹¤. crosstabì€ pivot tableì˜ íŠ¹ìˆ˜í•œ í˜•íƒœë¡œì„œ, **User-Item Rating Matrix**ë¥¼ ë§Œë“¤ ë•Œ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤.

```py
df_movie = pd.read_csv("./movie_rating.csv")
df_movie.head()
```

||critic|title|rating|
|---|---|---|---|
|0|Jack Matthews|Lady in the Water|3.0|
|1|Jack Matthews|Snakes on a Plane|4.0|
|2|Jack Matthews|You Me and Dupree|3.5|
|3|Jack Matthews|Superman Returns|5.0|
|4|Jack Matthews|The Night Listener|3.0|

```py
import pandas as pd

pd.crosstab(index = df_movie.critic, columns = df_movie.title,
            values = df_movie.rating, aggfunc="first").fillna(0)
```

![image](https://user-images.githubusercontent.com/91870042/144979707-494c8b77-2454-4f06-8883-06b3af9c3e67.png){: .align-center}

<br>

# Merge & Concat
## Merge
`Merge`ëŠ” 2ê°œì˜ ë°ì´í„°ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹  ë•Œ ì‚¬ìš©ë˜ë©°, SQLì—ì„œì˜ Mergeì™€ ë™ì¼í•œ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•œë‹¤.
```py
import pandas as pd

pd.merge(df_a, df_b, on = 'subject_id')
```
ë™ì¼í•œ ì¹¼ëŸ¼ì´ì§€ë§Œ, ë‘ ë°ì´í„° í”„ë ˆì„ì˜ ì¹¼ëŸ¼ëª…ì´ ë‹¤ë¥¼ ê²½ìš° ì™¼ìª½ì˜ ì¹¼ëŸ¼ëª…ê³¼ ì˜¤ë¥¸ìª½ ì¹¼ëŸ¼ëª…ì„ ì§€ì •í•˜ì—¬ mergeë¥¼ ìˆ˜í–‰í•œë‹¤.
```py
import pandas as pd

pd.merge(df_a, df_b, left_on='subject_id', rihgt_on='subject_id2')
```

### Join Method
`join`ì„ í•˜ëŠ” ë°©ë²•ì—ëŠ” 4ê°€ì§€ê°€ ì¡´ì¬í•œë‹¤.
- `inner join`: ë‘ ë°ì´í„° í”„ë ˆì„ì˜ êµì§‘í•©ì„ ë§í•œë‹¤.
- `full join`: ë‘ ë°ì´í„° í”„ë ˆì„ì˜ í•©ì§‘í•©ì„ ë§í•œë‹¤.
- `left join`: ë‘ ë°ì´í„° í”„ë ˆì„ ì¤‘ ì™¼ìª½ ë°ì´í„° í”„ë ˆì„ì„ ê¸°ì¤€ìœ¼ë¡œ joiní•œë‹¤. ê·¸ ì´ì™¸ì˜ ê°’ì€ NaNê°’ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.
- `right join`: ë‘ ë°ì´í„° í”„ë ˆì„ ì¤‘ ì˜¤ë¥¸ìª½ ë°ì´í„° í”„ë ˆì„ì„ ê¸°ì¤€ìœ¼ë¡œ joiní•œë‹¤. ê·¸ ì´ì™¸ì˜ ê°’ì€ NaNê°’ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤.

![image](https://user-images.githubusercontent.com/91870042/144987907-207373d1-2b9f-4982-aa88-b62ed6e0fd13.png){: width="50%" height="50%" .align-center}

```py
import pandas as pd

pd.merge(df_a, df_b, on='subject_id', how='left')
```
ìœ„ì—ì„œ ì…ë ¥ê°€ëŠ¥í•œ howì˜ ê°’ì—ëŠ” `outer`, `inner`, `left`, `right`ê°€ ìˆìœ¼ë©°, `inner`ê°€ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤.

### index based join
ë‘ ë°ì´í„° í”„ë ˆì„ì„ mergeí•˜ë©´ì„œ ì´ë¦„ì´ ê°™ì€ ì¹¼ëŸ¼ì´ ìˆì„ ê²½ìš° ì–´ëŠìª½ ë°ì´í„°í”„ë ˆì„ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡ì„ ê²ƒì¸ì§€ë¥¼ ì‘ì„±í•˜ëŠ”ë°, ê·¸ë•Œ ì„¤ì •í•˜ëŠ” ì˜µì…˜ì´ `right_index`, `left_index`ì´ë‹¤.

## Concat
`concat`ì€ ê°™ì€ í˜•íƒœë¥¼ ê°€ì§„ 2ê°œì˜ ë°ì´í„°í”„ë ˆì„ì„ ì„œë¡œ ë¶™ì´ëŠ” ì—°ì‚°ì‘ì—…ì´ë‹¤.
```py
df_new = pd.concat([df_a, df_b])
df_new.reset_index()

df_a.append(df_b)

# ì¶•ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜†ìœ¼ë¡œ concatë„ ê°€ëŠ¥í•˜ë‹¤.
df_new = pd.concat([df_a, df_b], axis = 1)
```
![image](https://user-images.githubusercontent.com/91870042/144981586-ef9af511-2bd1-4d46-9b77-210fe304cd9d.png){: .align-center}

<br>

# Persistence
## Database Connection
ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°ì„ í•´ì„œ ì›í•˜ëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°ì„ í• ë•ŒëŠ” ë³´í†µ `sqlite3`ë¥¼ ì‚¬ìš©ì„ í•˜ë©° importëŠ” ë‹¤ìŒê³¼ ê°™ì´ í•œë‹¤.
```py
import sqlite3
```

## XLS persistence
ë°ì´í„°í”„ë ˆì„ì˜ ì—‘ì…€ ì¶”ì¶œì½”ë“œì´ë‹¤. ì¼ë°˜ì ìœ¼ë¡œ `openpyxls`ë˜ëŠ” `XlsxWrite`ë¥¼ ì‚¬ìš©í•œë‹¤.

### ì—‘ì…€ë¡œë¶€í„° ë°ì´í„°í”„ë ˆì„ ë¶ˆëŸ¬ì˜¤ê¸°
```py
writer = pd.ExcelWriter('./data/df_routes.xlsx', engine='xlsxwriter')
df_routes.to_excel(writer, sheet_name='Sheet1')
```

## Pickle
`pickle`ì€ ê°€ì¥ ì¼ë°˜ì ì¸ pythoníŒŒì¼ persistenceì´ë‹¤.
- `to_pickle`: ë°ì´í„°í”„ë ˆì„ì„ pickleë¡œ ì €ì¥
- `read_pickle`: pickleíŒŒì¼ë¡œ ë¶€í„°, ë°ì´í„°í”„ë ˆì„ì„ ì½ì–´ì˜¤ê¸°

```py
df_routes.to_pickle("./data/df_routes.pickle")

df_routes.read_pickle("./data/df_routes.pickle")
df_routes.describe()
```